# translate.py
from __future__ import annotations

import json
from pathlib import Path
from typing import Any, Dict, List, Optional

from box_tools._share.openai_translate.translate import translate_flat_dict

from . import data


def run_translate(cfg: data.I18nConfig, incremental: bool = True) -> None:
    """
    å¢é‡ç¿»è¯‘ï¼ˆæ¨èé»˜è®¤ï¼‰ï¼š
      - ä»¥æ¯ä¸ªæ¨¡å—çš„ source æ–‡ä»¶ä¸ºæºï¼ˆæŒ‰ data.expected_i18n_filename ç”Ÿæˆï¼‰
      - å¯¹æ¯”å¯¹åº” target æ–‡ä»¶ï¼šç¼º key / ç©ºå­—ç¬¦ä¸² / None -> ç¿»è¯‘è¡¥é½ï¼›å¦åˆ™è·³è¿‡
      - ä»…å¤„ç†æ™®é€š keyï¼ˆå¿½ç•¥ @@* å…ƒå­—æ®µï¼‰
      - JSON å¿…é¡»æ˜¯ flatï¼ˆç”± data.read_json/write_json ä¿è¯ï¼‰

    å…¨é‡ç¿»è¯‘ï¼š
      - ä»¥ source ä¸ºåŸºå‡†ï¼Œè¦†ç›–ç”Ÿæˆ targetï¼ˆä»å¿½ç•¥ @@*ï¼Œä½†ä¼šä¿ç•™ target åŸæœ‰ @@*ï¼‰
    """
    if not cfg.i18n_dir.exists():
        raise FileNotFoundError(f"i18nDir ä¸å­˜åœ¨ï¼š{cfg.i18n_dir}")

    module_dirs = data.list_module_dirs(cfg.i18n_dir)
    if not module_dirs:
        print(f"âš ï¸ i18nDir ä¸‹æ²¡æœ‰ä¸šåŠ¡å­ç›®å½•ï¼š{cfg.i18n_dir}")
        return

    src_code = cfg.source_locale.code
    src_lang_name = cfg.source_locale.name_en  # ç”¨äº LLMï¼šEnglish
    model = cfg.openai_model

    targets = cfg.target_locales
    if not targets:
        print("âš ï¸ target_locales ä¸ºç©ºï¼Œè·³è¿‡ã€‚")
        return

    mode = "å¢é‡" if incremental else "å…¨é‡"
    print(f"ğŸŒ å¼€å§‹{mode}ç¿»è¯‘ï¼šsource={src_code}({src_lang_name}) -> {[t.code for t in targets]}")

    for md in module_dirs:
        src_file = md / data.expected_i18n_filename(md, src_code)
        if not src_file.exists():
            print(f"âš ï¸ è·³è¿‡æ¨¡å— {md.name}: ç¼ºå°‘ source æ–‡ä»¶ {src_file.name}")
            continue

        src_obj = data.read_json(src_file)  # âœ… ä¿è¯ flat
        src_kv = _normal_kv(src_obj)         # å»æ‰ @@*

        if not src_kv:
            print(f"âš ï¸ æ¨¡å— {md.name}: source æ— æ™®é€š keyï¼Œè·³è¿‡")
            continue

        for tgt in targets:
            tgt_code = tgt.code
            tgt_lang_name = tgt.name_en  # ç”¨äº LLMï¼šTraditional Chinese

            tgt_file = md / data.expected_i18n_filename(md, tgt_code)
            if tgt_file.exists():
                tgt_obj = data.read_json(tgt_file)
            else:
                # ç¼ºæ–‡ä»¶ä¹Ÿèƒ½ç¿»è¯‘ï¼šå…ˆç»™æœ€å°éª¨æ¶ï¼ˆ@@locale å›ºå®šç¬¬ä¸€ä½ç”± sort_json_keys ä¿è¯ï¼‰
                tgt_obj = {data.LOCALE_META_KEY: tgt_code}
                tgt_obj = data.sort_json_keys(tgt_obj)
                data.write_json(tgt_file, tgt_obj)

            tgt_kv = _normal_kv(tgt_obj)

            if incremental:
                need = _compute_incremental_pairs(src_kv, tgt_kv)
                if not need:
                    print(f"âœ… {md.name} / {tgt_file.name}: æ— éœ€ç¿»è¯‘")
                    continue
                src_for_translate = need
            else:
                # å…¨é‡ï¼šå…¨éƒ¨æ™®é€š key éƒ½ç¿»è¯‘
                src_for_translate = dict(src_kv)

            # åªç¿»è¯‘éç©ºå­—ç¬¦ä¸²ï¼ˆNone/ç©ºä¸²ä¸ç¿»ï¼‰
            src_for_translate = {k: v for k, v in src_for_translate.items() if isinstance(v, str) and v.strip()}
            if not src_for_translate:
                print(f"âš ï¸ {md.name} / {tgt_file.name}: æ— å¯ç¿»è¯‘å­—ç¬¦ä¸² key")
                continue

            prompt_en = _build_prompt_en(cfg, target_code=tgt_code)

            print(f"â¡ï¸  {md.name} / {tgt_file.name}: ç¿»è¯‘ {len(src_for_translate)} ä¸ª key...")

            out = translate_flat_dict(
                prompt_en=prompt_en,
                src_dict=src_for_translate,
                src_lang=src_lang_name,      # âœ… ç”¨ name_en
                tgt_locale=tgt_lang_name,    # âœ… ç”¨ name_en
                model=model,
                api_key=None,                # âœ… ä¸å…³å¿ƒ OPENAI_API_KEY
            )

            # åˆå¹¶å› targetï¼šä¿ç•™ target çš„ @@* å…ƒå­—æ®µï¼Œæ›´æ–°/è¦†ç›–æ™®é€š key
            merged = dict(tgt_obj)  # åŒ…å« @@locale ç­‰å…ƒå­—æ®µ
            for k, v in out.items():
                if data.is_meta_key(k):
                    continue
                merged[k] = v

            # è®© @@locale å›ºå®šç¬¬ä¸€ä½ + å…¶å®ƒ key æ’åºï¼ˆä¸ sort è§„åˆ™ä¸€è‡´ï¼‰
            merged = data.sort_json_keys(merged)
            data.write_json(tgt_file, merged)

            print(f"âœ… å†™å…¥ {tgt_file}")

    print("ğŸ‰ ç¿»è¯‘å®Œæˆã€‚")


def _normal_kv(obj: Dict[str, Any]) -> Dict[str, Any]:
    """åªä¿ç•™æ™®é€š keyï¼ˆæ’é™¤ @@*ï¼‰ã€‚"""
    return {k: v for k, v in obj.items() if not data.is_meta_key(k)}


def _compute_incremental_pairs(src: Dict[str, Any], tgt: Dict[str, Any]) -> Dict[str, str]:
    """
    å¢é‡ï¼šsrc æœ‰ï¼Œtgt ç¼º / None / ç©ºå­—ç¬¦ä¸² -> éœ€è¦ç¿»è¯‘
    """
    out: Dict[str, str] = {}
    for k, v in src.items():
        if k not in tgt:
            out[k] = v
            continue
        tv = tgt.get(k)
        if tv is None:
            out[k] = v
            continue
        if isinstance(tv, str) and not tv.strip():
            out[k] = v
            continue
    return out


def _build_prompt_en(cfg: data.I18nConfig, target_code: str) -> Optional[str]:
    """
    prompt è§„åˆ™ï¼š
    - prompts.default_en
    - prompts.by_locale_en[code]ï¼ˆå¯é€‰ï¼‰
    translate_flat_dict ä¼šæŠŠ prompt_en æ‹¼è¿› system prompt
    """
    prompts = cfg.prompts or {}
    default_en = (prompts.get("default_en") or "").strip()
    by_locale_en = prompts.get("by_locale_en") or {}
    extra = (by_locale_en.get(target_code) or "").strip() if isinstance(by_locale_en, dict) else ""

    parts = [p for p in [default_en, extra] if p]
    return "\n\n".join(parts) if parts else None
