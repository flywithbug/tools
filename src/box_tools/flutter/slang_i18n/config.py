from __future__ import annotations

from pathlib import Path
from typing import Any, Dict, List

from box_tools._share.openai_translate.models import OpenAIModel
from .model import Locale, Options, Prompts, ProjectConfig

CONFIG_FILE = "slang_i18n.yaml"

ALLOWED_OPENAI_MODELS = (
    "gpt-4o",
    "gpt-4o-mini",
    "gpt-4.1",
    "gpt-4.1-mini",
)


def _require_yaml():
    try:
        import yaml  # type: ignore
        return yaml
    except Exception:
        raise SystemExit(
            "âŒ ç¼ºå°‘ä¾èµ– PyYAMLï¼ˆimport yaml å¤±è´¥ï¼‰\n"
            "ä¿®å¤æ–¹å¼ï¼š\n"
            "1) pipx å®‰è£…ï¼špipx inject box pyyaml\n"
            "2) æˆ–åœ¨ pyproject.toml dependencies åŠ å…¥ PyYAML>=6.0 åé‡æ–°å‘å¸ƒ/å®‰è£…\n"
        )


def _schema_error(msg: str) -> ValueError:
    return ValueError(
        "slang_i18n.yaml æ ¼å¼é”™è¯¯ï¼š\n"
        f"- {msg}\n\n"
        "æœŸæœ›ç»“æ„ï¼ˆæ–° schemaï¼‰ç¤ºä¾‹ï¼š\n"
        "openAIModel: gpt-4o\n"
        "source_locale:\n"
        "  code: en\n"
        "  name_en: English\n"
        "target_locales:\n"
        "  - code: zh_Hant\n"
        "    name_en: Traditional Chinese\n"
        "prompts:\n"
        "  default_en: |\n"
        "    Translate UI strings naturally.\n"
        "  by_locale_en:\n"
        "    zh_Hant: |\n"
        "      Use Taiwan Traditional Chinese UI style.\n"
        "options:\n"
        "  sort_keys: true\n"
        "  cleanup_extra_keys: true\n"
        "  incremental_translate: true\n"
        "  normalize_filenames: true\n"
    )


def _need_nonempty_str(obj: Dict[str, Any], key: str, path: str) -> str:
    v = obj.get(key)
    if not isinstance(v, str) or not v.strip():
        raise _schema_error(f"{path}.{key} å¿…é¡»æ˜¯éç©ºå­—ç¬¦ä¸²")
    return v.strip()


def _need_bool(obj: Dict[str, Any], key: str, path: str) -> bool:
    v = obj.get(key)
    if not isinstance(v, bool):
        raise _schema_error(f"{path}.{key} å¿…é¡»æ˜¯ boolï¼ˆtrue/falseï¼‰")
    return v


def _need_openai_model(cfg: Dict[str, Any]) -> str:
    v = cfg.get("openAIModel", OpenAIModel.GPT_4O.value)
    if v is None:
        v = OpenAIModel.GPT_4O.value
    if not isinstance(v, str) or not v.strip():
        raise _schema_error("openAIModel å¿…é¡»æ˜¯éç©ºå­—ç¬¦ä¸²")
    v = v.strip()
    if v not in set(ALLOWED_OPENAI_MODELS):
        raise _schema_error(f"openAIModel ä¸åˆæ³•ï¼š{v!r}ï¼Œå¯é€‰ï¼š{', '.join(ALLOWED_OPENAI_MODELS)}")
    return v


def validate_config(raw: Any) -> ProjectConfig:
    if not isinstance(raw, dict):
        raise _schema_error("æ ¹èŠ‚ç‚¹å¿…é¡»æ˜¯ YAML object/map")

    openai_model = _need_openai_model(raw)

    src_raw = raw.get("source_locale")
    if not isinstance(src_raw, dict):
        raise _schema_error("source_locale å¿…é¡»æ˜¯ object/mapï¼ˆåŒ…å« code / name_enï¼‰")
    src = Locale(
        code=_need_nonempty_str(src_raw, "code", "source_locale"),
        name_en=_need_nonempty_str(src_raw, "name_en", "source_locale"),
    )

    targets_raw = raw.get("target_locales")
    if not isinstance(targets_raw, list) or not targets_raw:
        raise _schema_error("target_locales å¿…é¡»æ˜¯éç©ºæ•°ç»„ï¼ˆæ¯é¡¹ä¸º {code, name_en}ï¼‰")

    seen: set[str] = set()
    targets: List[Locale] = []
    for i, it in enumerate(targets_raw):
        if not isinstance(it, dict):
            raise _schema_error(f"target_locales[{i}] å¿…é¡»æ˜¯ object/mapï¼ˆåŒ…å« code / name_enï¼‰")
        code = _need_nonempty_str(it, "code", f"target_locales[{i}]")
        name_en = _need_nonempty_str(it, "name_en", f"target_locales[{i}]")
        if code == src.code:
            raise _schema_error(f"target_locales[{i}].code ä¸åº”ç­‰äº source_locale.codeï¼ˆ{src.code}ï¼‰")
        if code in seen:
            raise _schema_error(f"target_locales[{i}].code é‡å¤ï¼š{code}")
        seen.add(code)
        targets.append(Locale(code=code, name_en=name_en))

    prompts_raw = raw.get("prompts") or {}
    if not isinstance(prompts_raw, dict):
        raise _schema_error("prompts å¿…é¡»æ˜¯ object/mapï¼ˆå¯çœç•¥ï¼‰")
    default_en = prompts_raw.get("default_en") or ""
    if not isinstance(default_en, str):
        raise _schema_error("prompts.default_en å¿…é¡»æ˜¯å­—ç¬¦ä¸²ï¼ˆå¯ä¸ºç©ºï¼‰")
    by_locale_raw = prompts_raw.get("by_locale_en") or {}
    if not isinstance(by_locale_raw, dict):
        raise _schema_error("prompts.by_locale_en å¿…é¡»æ˜¯ object/mapï¼ˆå¯çœç•¥ï¼‰")
    by_locale: Dict[str, str] = {}
    for k, v in by_locale_raw.items():
        if not isinstance(k, str) or not k.strip():
            raise _schema_error("prompts.by_locale_en çš„ key å¿…é¡»æ˜¯éç©ºå­—ç¬¦ä¸²ï¼ˆlocale codeï¼‰")
        if not isinstance(v, str):
            raise _schema_error(f"prompts.by_locale_en[{k!r}] å¿…é¡»æ˜¯å­—ç¬¦ä¸²")
        by_locale[k.strip()] = v
    prompts = Prompts(default_en=default_en, by_locale_en=by_locale)

    opts_raw = raw.get("options")
    if not isinstance(opts_raw, dict):
        raise _schema_error("options å¿…é¡»æ˜¯ object/map")
    normalize_filenames = opts_raw.get("normalize_filenames", True)
    if not isinstance(normalize_filenames, bool):
        raise _schema_error("options.normalize_filenames å¿…é¡»æ˜¯ boolï¼ˆtrue/falseï¼‰")

    options = Options(
        sort_keys=_need_bool(opts_raw, "sort_keys", "options"),
        cleanup_extra_keys=_need_bool(opts_raw, "cleanup_extra_keys", "options"),
        incremental_translate=_need_bool(opts_raw, "incremental_translate", "options"),
        normalize_filenames=normalize_filenames,
    )

    return ProjectConfig(
        openai_model=openai_model,
        source_locale=src,
        target_locales=targets,
        prompts=prompts,
        options=options,
    )


def read_config(path: Path) -> ProjectConfig:
    yaml = _require_yaml()
    raw = yaml.safe_load(path.read_text(encoding="utf-8"))
    return validate_config(raw)


def read_config_or_throw(path: Path) -> ProjectConfig:
    if not path.exists():
        raise FileNotFoundError(f"âŒ æœªæ‰¾åˆ° {CONFIG_FILE}ï¼ˆè¯·å…ˆ slang_i18n initï¼‰")
    return read_config(path)


def _config_template_text() -> str:
    # ç›´æ¥æ²¿ç”¨ä½ ç°æœ‰è„šæœ¬çš„æ¨¡æ¿ï¼ˆä¿ç•™æ³¨é‡Šï¼‰ï¼Œé¿å…ç”¨æˆ·è¿ç§»æˆæœ¬:contentReference[oaicite:1]{index=1}
    from textwrap import dedent
    return dedent(
        """\
        # slang_i18n.yaml
        # Flutter slang i18n é…ç½®ï¼ˆNEW schemaï¼‰
        #
        # ç›®å½•çº¦å®šï¼š
        # - åœ¨é¡¹ç›®æ ¹ç›®å½•æ‰§è¡Œ
        # - i18n/ ç›®å½•å­˜åœ¨
        # - è‹¥ i18n/ ä¸‹å­˜åœ¨å­ç›®å½•ï¼šåªå¤„ç†å­ç›®å½•ä¸­çš„ *.i18n.jsonï¼ˆè§†ä¸ºæ¨¡å—ï¼‰
        # - è‹¥ i18n/ ä¸‹æ— å­ç›®å½•ï¼šå¤„ç† i18n/ æ ¹ç›®å½•ä¸­çš„ *.i18n.json

        # OpenAI æ¨¡å‹ï¼ˆé»˜è®¤ gpt-4oï¼‰
        # å¯é€‰å€¼ï¼ˆæšä¸¾ï¼‰ï¼š
        # - gpt-4o
        # - gpt-4o-mini
        # - gpt-4.1
        # - gpt-4.1-mini
        openAIModel: gpt-4o

        # æºè¯­è¨€ï¼ˆç»“æ„åŒ–ï¼šcode + è‹±æ–‡è¯­è¨€åï¼‰
        source_locale:
          code: en
          name_en: English

        # ç›®æ ‡è¯­è¨€åˆ—è¡¨ï¼šæ¯é¡¹åŒ…å« code + è‹±æ–‡è¯­è¨€å
        target_locales:
          - code: zh_Hant
            name_en: Traditional Chinese
          - code: ja
            name_en: Japanese
          - code: ko
            name_en: Korean
          - code: fr
            name_en: French

        prompts:
          default_en: |
            Translate UI strings naturally for a mobile app.
            Be concise, clear, and consistent.

          by_locale_en:
            zh_Hant: |
              Use Taiwan Traditional Chinese UI style.

        options:
          sort_keys: true
          cleanup_extra_keys: true
          incremental_translate: true
          normalize_filenames: true
        """
    )


def init_config(path: Path) -> None:
    _require_yaml()
    if path.exists():
        _ = read_config(path)  # å­˜åœ¨å°±æ ¡éªŒï¼Œä¸è¦†ç›–
        print(f"âœ… {CONFIG_FILE} å·²å­˜åœ¨ä¸”æ ¼å¼æ­£ç¡®ï¼ˆä¸ä¼šè¦†ç›–ï¼‰")
        return
    path.write_text(_config_template_text(), encoding="utf-8")
    print(f"ğŸ“ å·²ç”Ÿæˆ {CONFIG_FILE}ï¼ˆæ–° schemaï¼Œå«æ³¨é‡Šï¼‰")
