from __future__ import annotations

import argparse
import json
import os
import re
import sys
import time
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, Iterable, List, Optional, Tuple

try:
    from openai import OpenAI  # noqa: F401
except Exception:
    OpenAI = None  # type: ignore

# âœ… ä½¿ç”¨åŒç›®å½•ä¸‹ gpt æ¨¡å—
from .comm.translate import OpenAIModel, TranslationError, translate_flat_dict  # type: ignore


BOX_TOOL = {
    "id": "flutter.slang_i18n",
    "name": "slang_i18n",
    "category": "flutter",
    "summary": "Flutter slang i18nï¼ˆflat .i18n.jsonï¼‰æ’åº / å†—ä½™æ£€æŸ¥æ¸…ç† / å¢é‡ç¿»è¯‘ï¼ˆæ”¯æŒäº¤äº’ï¼‰",
    "usage": [
        "slang_i18n",
        "slang_i18n init",
        "slang_i18n doctor",
        "slang_i18n sort",
        "slang_i18n check",
        "slang_i18n clean --yes",
        "slang_i18n translate --api-key $OPENAI_API_KEY",
    ],
    "options": [
        {"flag": "--api-key", "desc": "OpenAI API keyï¼ˆä¹Ÿå¯ç”¨ç¯å¢ƒå˜é‡ OPENAI_API_KEYï¼‰"},
        {"flag": "--model", "desc": "æ¨¡å‹ï¼ˆé»˜è®¤ gpt-4oï¼‰"},
        {"flag": "--full", "desc": "å…¨é‡ç¿»è¯‘ï¼ˆé»˜è®¤å¢é‡ç¿»è¯‘ï¼‰"},
        {"flag": "--yes", "desc": "clean åˆ é™¤å†—ä½™æ—¶è·³è¿‡ç¡®è®¤"},
        {"flag": "--no-exitcode-3", "desc": "check å‘ç°å†—ä½™æ—¶ä»è¿”å› 0ï¼ˆé»˜è®¤è¿”å› 3ï¼‰"},
    ],
    "examples": [
        {"cmd": "slang_i18n init", "desc": "ç”Ÿæˆ slang_i18n.yaml æ¨¡æ¿"},
        {"cmd": "slang_i18n translate --api-key $OPENAI_API_KEY", "desc": "å¢é‡ç¿»è¯‘ç¼ºå¤±çš„ keys"},
        {"cmd": "slang_i18n clean --yes", "desc": "åˆ é™¤æ‰€æœ‰å†—ä½™ keyï¼ˆä¸è¯¢é—®ï¼‰"},
    ],
    "dependencies": [
        "PyYAML>=6.0",
        "openai>=1.0.0",
    ],
}


CONFIG_FILE = "slang_i18n.yaml"
I18N_DIR = "i18n"

# é»˜è®¤è¯­è¨€é›†åˆ
DEFAULT_ALL_LOCALES = [
    "en",
    "zh_Hant",
    "de",
    "es",
    "fil",
    "fr",
    "hi",
    "id",
    "ja",
    "kk",
    "ko",
    "pt",
    "ru",
    "th",
    "uk",
    "vi",
    "tr",
    "nl",
]
DEFAULT_SOURCE_LOCALE = "en"
DEFAULT_TARGET_LOCALES = [x for x in DEFAULT_ALL_LOCALES if x != DEFAULT_SOURCE_LOCALE]

DEFAULT_CONFIG: Dict[str, Any] = {
    "source_locale": DEFAULT_SOURCE_LOCALE,
    "target_locales": DEFAULT_TARGET_LOCALES,
    "prompt_en": "",
    "options": {
        "sort_keys": True,
        "cleanup_extra_keys": True,
        "incremental_translate": True,
        "normalize_filenames": True,
    },
}

# Exit codes
EXIT_OK = 0
EXIT_FAIL = 1
EXIT_BAD = 2
EXIT_REDUNDANT_FOUND = 3


# =========================================================
# Lazy import for PyYAML
# =========================================================
def _require_yaml():
    try:
        import yaml  # type: ignore

        return yaml
    except Exception:
        raise SystemExit(
            "âŒ ç¼ºå°‘ä¾èµ– PyYAMLï¼ˆimport yaml å¤±è´¥ï¼‰\n"
            "ä¿®å¤æ–¹å¼ï¼š\n"
            "1) pipx å®‰è£…ï¼špipx inject box pyyaml\n"
            "2) æˆ–åœ¨ pyproject.toml dependencies åŠ å…¥ PyYAML>=6.0 åé‡æ–°å‘å¸ƒ/å®‰è£…\n"
        )


# =========================================================
# Config validate
# =========================================================
def _schema_error(msg: str) -> ValueError:
    return ValueError(
        "slang_i18n.yaml æ ¼å¼é”™è¯¯ï¼š\n" f"- {msg}\n\n"
        "æœŸæœ›ç»“æ„ç¤ºä¾‹ï¼š\n"
        "source_locale: en\n"
        "target_locales:\n"
        "  - zh_Hant\n"
        "  - ja\n"
        "prompt_en: |\n"
        "  Translate UI strings naturally.\n"
        "options:\n"
        "  sort_keys: true\n"
        "  cleanup_extra_keys: true\n"
        "  incremental_translate: true\n"
        "  normalize_filenames: true\n"
    )


def validate_config(cfg: Any) -> Dict[str, Any]:
    if not isinstance(cfg, dict):
        raise _schema_error("æ ¹èŠ‚ç‚¹å¿…é¡»æ˜¯ YAML object/map")

    src = cfg.get("source_locale")
    if not isinstance(src, str) or not src.strip():
        raise _schema_error("source_locale å¿…é¡»æ˜¯éç©ºå­—ç¬¦ä¸²ï¼Œä¾‹å¦‚ en")
    src = src.strip()

    targets = cfg.get("target_locales")
    if not isinstance(targets, list) or not targets:
        raise _schema_error("target_locales å¿…é¡»æ˜¯éç©ºæ•°ç»„")
    targets2: List[str] = []
    for i, t in enumerate(targets):
        if not isinstance(t, str) or not t.strip():
            raise _schema_error(f"target_locales[{i}] å¿…é¡»æ˜¯éç©ºå­—ç¬¦ä¸²")
        targets2.append(t.strip())

    if src in targets2:
        raise _schema_error(f"target_locales ä¸åº”åŒ…å« source_localeï¼ˆå½“å‰ source_locale={src}ï¼‰")

    prompt_en = cfg.get("prompt_en", "")
    if prompt_en is None:
        prompt_en = ""
    if not isinstance(prompt_en, str):
        raise _schema_error("prompt_en å¿…é¡»æ˜¯å­—ç¬¦ä¸²ï¼ˆå¯ä¸ºç©ºï¼‰")

    opts = cfg.get("options")
    if not isinstance(opts, dict):
        raise _schema_error("options å¿…é¡»æ˜¯ object/map")

    def need_bool(key: str) -> bool:
        v = opts.get(key)
        if not isinstance(v, bool):
            raise _schema_error(f"options.{key} å¿…é¡»æ˜¯ boolï¼ˆtrue/falseï¼‰")
        return v

    normalize_filenames = opts.get("normalize_filenames", True)
    if not isinstance(normalize_filenames, bool):
        raise _schema_error("options.normalize_filenames å¿…é¡»æ˜¯ boolï¼ˆtrue/falseï¼‰")

    return {
        "source_locale": src,
        "target_locales": targets2,
        "prompt_en": prompt_en,
        "options": {
            "sort_keys": need_bool("sort_keys"),
            "cleanup_extra_keys": need_bool("cleanup_extra_keys"),
            "incremental_translate": need_bool("incremental_translate"),
            "normalize_filenames": normalize_filenames,
        },
    }


def read_config(path: Path) -> Dict[str, Any]:
    yaml = _require_yaml()
    raw = yaml.safe_load(path.read_text(encoding="utf-8"))
    return validate_config(raw)


def read_config_or_throw(path: Path) -> Dict[str, Any]:
    if not path.exists():
        raise FileNotFoundError(f"âŒ æœªæ‰¾åˆ° {CONFIG_FILE}ï¼ˆè¯·å…ˆ slang_i18n initï¼‰")
    return read_config(path)


def init_config(path: Path) -> None:
    yaml = _require_yaml()
    if path.exists():
        _ = read_config(path)  # å­˜åœ¨å°±æ ¡éªŒï¼Œä¸è¦†ç›–
        print(f"âœ… {CONFIG_FILE} å·²å­˜åœ¨ä¸”æ ¼å¼æ­£ç¡®ï¼ˆä¸ä¼šè¦†ç›–ï¼‰")
        return

    path.write_text(
        yaml.safe_dump(DEFAULT_CONFIG, sort_keys=False, allow_unicode=True),
        encoding="utf-8",
    )
    print(f"ğŸ“ å·²ç”Ÿæˆ {CONFIG_FILE}ï¼ˆè¯·æŒ‰éœ€ä¿®æ”¹ï¼‰")


# =========================================================
# i18n scanning helpers
# =========================================================
def ensure_i18n_dir() -> Path:
    p = Path.cwd() / I18N_DIR
    if not p.exists() or not p.is_dir():
        raise FileNotFoundError("âŒ å½“å‰ç›®å½•æœªæ‰¾åˆ° i18n/ï¼ˆè¯·åœ¨é¡¹ç›®æ ¹ç›®å½•æ‰§è¡Œï¼‰")
    return p


def _has_any_subdir(i18n_dir: Path) -> bool:
    return any(c.is_dir() for c in i18n_dir.iterdir())


def get_active_groups(i18n_dir: Path) -> List[Path]:
    """è§„åˆ™ï¼š
    - i18n/ ä¸‹å¦‚æœå­˜åœ¨ä»»ä½•å­ç›®å½•ï¼šåªå¤„ç†å­ç›®å½•ï¼Œä¸å¤„ç† i18n/ æ ¹ç›®å½•
    - å¦åˆ™ï¼ˆæ²¡æœ‰å­ç›®å½•ï¼‰ï¼šå¤„ç† i18n/ æ ¹ç›®å½•
    """
    subdirs = [c for c in i18n_dir.iterdir() if c.is_dir()]
    if subdirs:
        return sorted(subdirs)
    return [i18n_dir]


# =========================================================
# Filename helpers (camelCase folder + _locale suffix)
# =========================================================
def _to_camel(s: str) -> str:
    parts = [p for p in re.split(r"[_\-\s]+", s.strip()) if p]
    if not parts:
        return s
    head = parts[0].lower()
    tail = "".join(p[:1].upper() + p[1:] for p in parts[1:])
    return head + tail


def group_file_name(group: Path, locale: str) -> Path:
    """è§„åˆ™ï¼š
    - i18n/ æ ¹ç›®å½•ï¼š{locale}.i18n.json
    - i18n/<module>/ï¼š{camelFolder}_{locale}.i18n.json
    """
    if group.name == I18N_DIR:
        return group / f"{locale}.i18n.json"

    prefix = _to_camel(group.name)
    return group / f"{prefix}_{locale}.i18n.json"


# =========================================================
# JSON helpers (meta/body split)
# =========================================================
def load_json_obj(path: Path) -> Dict[str, Any]:
    """
    è¯»å– JSON objectã€‚è‹¥ JSON è§£æå¤±è´¥ï¼Œä¼šè¾“å‡ºï¼š
    - å…·ä½“æ–‡ä»¶ path
    - é”™è¯¯åŸå› ï¼ˆe.msgï¼‰
    - è¡Œ/åˆ—/char ä½ç½®
    - é”™è¯¯è¡Œé™„è¿‘ä¸Šä¸‹æ–‡ï¼ˆå¸¦æŒ‡é’ˆï¼‰
    """
    text = path.read_text(encoding="utf-8")

    try:
        obj = json.loads(text)
    except json.JSONDecodeError as e:
        line = e.lineno
        col = e.colno
        lines = text.splitlines()

        # ä¸Šä¸‹æ–‡ï¼šé”™è¯¯è¡Œå‰åå„ 2 è¡Œ
        start = max(1, line - 2)
        end = min(len(lines), line + 2)

        ctx: List[str] = []
        for i in range(start, end + 1):
            prefix = ">>" if i == line else "  "
            ctx.append(f"{prefix} {i:4d} | {lines[i-1]}")

        # æŒ‡é’ˆï¼šå°½é‡å¯¹é½åˆ°æ˜¾ç¤ºè¡Œ
        # è¯´æ˜ï¼šè¿™é‡Œç”¨ä¸€ä¸ªç»éªŒåç§»ï¼Œè®© ^ å‡ºç°åœ¨ â€œ| â€ åçš„åˆ—é™„è¿‘
        pointer = " " * (col + 8) + "^"
        ctx.append(pointer)

        raise ValueError(
            "âŒ JSON è§£æå¤±è´¥\n"
            f"- file: {path}\n"
            f"- error: {e.msg}\n"
            f"- at: line {line}, column {col} (char {e.pos})\n"
            "----- context -----\n"
            + "\n".join(ctx)
            + "\n-------------------"
        ) from None

    if not isinstance(obj, dict):
        raise ValueError(f"âŒ JSON å¿…é¡»æ˜¯ objectï¼š{path}")
    return obj


def split_slang_json(path: Path, obj: Dict[str, Any]) -> Tuple[Dict[str, Any], Dict[str, str]]:
    """slang flat json:
    - æ‰€æœ‰ä»¥ @@ å¼€å¤´çš„æ˜¯ metadataï¼Œä¸ç¿»è¯‘
    - å…¶ä½™ key å¿…é¡»æ˜¯ str -> str
    """
    meta: Dict[str, Any] = {}
    body: Dict[str, str] = {}

    for k, v in obj.items():
        if not isinstance(k, str):
            raise ValueError(f"âŒ éæ³• keyï¼ˆéå­—ç¬¦ä¸²ï¼‰ï¼š{path}")

        if k.startswith("@@"):
            meta[k] = v
            continue

        if not isinstance(v, str):
            raise ValueError(
                f"âŒ ä»…æ”¯æŒå¹³é“º string->stringï¼š{path}ï¼Œkey={k!r} value_type={type(v).__name__}"
            )
        body[k] = v

    return meta, body


def save_json(path: Path, meta: Dict[str, Any], body: Dict[str, str], sort_keys: bool) -> None:
    """è¾“å‡ºé¡ºåºï¼š
    1) @@localeï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    2) å…¶å®ƒ @@metaï¼ˆæŒ‰ key æ’åºï¼‰
    3) æ™®é€š keyï¼ˆæŒ‰ key æ’åºå¯é€‰ï¼‰
    """
    out: Dict[str, Any] = {}

    if "@@locale" in meta:
        out["@@locale"] = meta.get("@@locale")

    other_meta_keys = sorted([k for k in meta.keys() if k != "@@locale"])
    for k in other_meta_keys:
        out[k] = meta[k]

    if sort_keys:
        for k, v in sorted(body.items(), key=lambda kv: kv[0]):
            out[k] = v
    else:
        for k, v in body.items():
            out[k] = v

    path.write_text(json.dumps(out, ensure_ascii=False, indent=2) + "\n", encoding="utf-8")


# =========================================================
# Filename normalization (accurate + conservative)
# =========================================================
def _match_locale_from_filename(filename: str, locales_sorted: List[str]) -> Optional[str]:
    if not filename.endswith(".i18n.json"):
        return None

    stem = filename[: -len(".i18n.json")]

    for loc in locales_sorted:
        if stem.endswith(f"_{loc}"):
            return loc
        if stem == loc:
            return loc

    return None


def normalize_group_filenames(group: Path, locales: List[str], verbose: bool = True) -> None:
    """åªè§„èŒƒåŒ– i18n/<module>/ ä¸‹çš„æ–‡ä»¶åï¼š{camelFolder}_{locale}.i18n.json

    åªå¯¹â€œèƒ½ä»æ–‡ä»¶åæ˜ç¡®è¯†åˆ« localeâ€çš„æ–‡ä»¶åŠ¨æ‰‹ï¼›ä¸è¦†ç›–å·²æœ‰ç›®æ ‡æ–‡ä»¶ã€‚
    """
    if group.name == I18N_DIR:
        return

    locales_sorted = sorted(set(locales), key=len, reverse=True)
    expected_prefix_camel = _to_camel(group.name)

    for p in group.glob("*.i18n.json"):
        loc = _match_locale_from_filename(p.name, locales_sorted)
        if not loc:
            continue

        expected_name = f"{expected_prefix_camel}_{loc}.i18n.json"
        if p.name == expected_name:
            continue

        target = group / expected_name
        if target.exists():
            if verbose:
                print(f"âš ï¸ è·³è¿‡é‡å‘½åï¼ˆç›®æ ‡å·²å­˜åœ¨ï¼‰ï¼š{p.name} -> {target.name}")
            continue

        if verbose:
            print(f"ğŸ› ï¸ é‡å‘½åï¼š{p.name} -> {target.name}")
        p.rename(target)


# =========================================================
# Ensure language files
# =========================================================
def ensure_language_files_in_group(group: Path, src_locale: str, targets: List[str]) -> None:
    """åªåˆ›å»ºç¼ºå¤±çš„æ–‡ä»¶ï¼Œåˆ›å»ºå†…å®¹ä»…åŒ…å« @@locale"""
    sort_keys = False

    src_path = group_file_name(group, src_locale)
    if not src_path.exists():
        save_json(src_path, {"@@locale": src_locale}, {}, sort_keys=sort_keys)
        print(f"â• Created {src_path}")

    for loc in targets:
        p = group_file_name(group, loc)
        if not p.exists():
            save_json(p, {"@@locale": loc}, {}, sort_keys=sort_keys)
            print(f"â• Created {p}")


def ensure_all_language_files(i18n_dir: Path, cfg: Dict[str, Any]) -> None:
    groups = get_active_groups(i18n_dir)
    locales = [cfg["source_locale"], *cfg["target_locales"]]

    if bool(cfg["options"].get("normalize_filenames", True)):
        for g in groups:
            normalize_group_filenames(g, locales=locales, verbose=True)

    for g in groups:
        ensure_language_files_in_group(g, cfg["source_locale"], cfg["target_locales"])


# =========================================================
# Sort
# =========================================================
def sort_all_json(i18n_dir: Path, sort_keys: bool) -> None:
    for g in get_active_groups(i18n_dir):
        for p in g.glob("*.i18n.json"):
            meta, body = split_slang_json(p, load_json_obj(p))
            save_json(p, meta, body, sort_keys=sort_keys)


# =========================================================
# Redundant check/delete (only body keys)
# =========================================================
@dataclass
class RedundantItem:
    group: str
    file: Path
    locale: str
    extra_keys: List[str]


def collect_redundant(cfg: Dict[str, Any], i18n_dir: Path) -> List[RedundantItem]:
    src_locale = cfg["source_locale"]
    targets = cfg["target_locales"]

    items: List[RedundantItem] = []
    for group in get_active_groups(i18n_dir):
        module_name = group.name if group.name != I18N_DIR else "i18n"

        src_path = group_file_name(group, src_locale)
        try:
            _, src_body = split_slang_json(src_path, load_json_obj(src_path))
        except Exception as e:
            raise ValueError(
                "âŒ è¯»å–æºè¯­è¨€æ–‡ä»¶å¤±è´¥\n"
                f"- module={module_name}\n"
                f"- locale={src_locale}\n"
                f"- file={src_path}\n"
                f"{e}"
            ) from None

        src_keys = set(src_body.keys())

        for loc in targets:
            tgt_path = group_file_name(group, loc)
            try:
                _, tgt_body = split_slang_json(tgt_path, load_json_obj(tgt_path))
            except Exception as e:
                raise ValueError(
                    "âŒ è¯»å–ç›®æ ‡è¯­è¨€æ–‡ä»¶å¤±è´¥\n"
                    f"- module={module_name}\n"
                    f"- locale={loc}\n"
                    f"- file={tgt_path}\n"
                    f"{e}"
                ) from None

            tgt_keys = set(tgt_body.keys())

            extra = sorted(tgt_keys - src_keys)
            if extra:
                items.append(
                    RedundantItem(
                        group=module_name,
                        file=tgt_path,
                        locale=loc,
                        extra_keys=extra,
                    )
                )
    return items


def report_redundant(items: List[RedundantItem], max_keys_preview: int = 40) -> None:
    if not items:
        print("âœ… æœªå‘ç°å†—ä½™ key")
        return

    total_keys = sum(len(x.extra_keys) for x in items)
    print(f"âš ï¸ å‘ç°å†—ä½™ï¼š{len(items)} ä¸ªæ–‡ä»¶ï¼Œåˆè®¡ {total_keys} ä¸ª key\n")
    for it in items:
        preview = it.extra_keys[:max_keys_preview]
        more = len(it.extra_keys) - len(preview)
        print(f"- module={it.group} locale={it.locale} file={it.file}")
        for k in preview:
            print(f"    â€¢ {k}")
        if more > 0:
            print(f"    â€¦ and {more} more")
        print("")


def delete_redundant(items: List[RedundantItem], sort_keys: bool) -> None:
    for it in items:
        meta, body = split_slang_json(it.file, load_json_obj(it.file))
        for k in it.extra_keys:
            body.pop(k, None)
        save_json(it.file, meta, body, sort_keys=sort_keys)
        print(f"ğŸ—‘ï¸ Removed {len(it.extra_keys)} keys from {it.file}")


# =========================================================
# Progress (group/locale level)
# =========================================================
@dataclass
class Progress:
    total_keys: int
    done_keys: int = 0
    started_at: float = 0.0

    def __post_init__(self) -> None:
        if self.started_at <= 0:
            self.started_at = time.time()

    def bump(self, n: int) -> None:
        self.done_keys += max(0, n)

    def percent(self) -> int:
        if self.total_keys <= 0:
            return 100
        return int(self.done_keys * 100 / self.total_keys)

    def eta_text(self) -> str:
        if self.total_keys <= 0 or self.done_keys <= 0:
            return "ETA: --"
        elapsed = time.time() - self.started_at
        rate = self.done_keys / max(elapsed, 1e-6)
        remain = max(self.total_keys - self.done_keys, 0)
        sec = int(remain / max(rate, 1e-6))
        if sec < 60:
            return f"ETA: {sec}s"
        if sec < 3600:
            return f"ETA: {sec//60}m{sec%60:02d}s"
        return f"ETA: {sec//3600}h{(sec%3600)//60:02d}m"


def _compute_need_for_one(group: Path, cfg: Dict[str, Any], loc: str, incremental: bool, cleanup_extra: bool) -> int:
    src_locale = cfg["source_locale"]
    src_path = group_file_name(group, src_locale)
    tgt_path = group_file_name(group, loc)

    _, src_body = split_slang_json(src_path, load_json_obj(src_path))
    _, tgt_body = split_slang_json(tgt_path, load_json_obj(tgt_path))

    if cleanup_extra:
        tgt_body = {k: v for k, v in tgt_body.items() if k in src_body}

    need = {k: v for k, v in src_body.items() if k not in tgt_body} if incremental else dict(src_body)
    return len(need)


# =========================================================
# Translation
# =========================================================
def translate_group(
        group: Path,
        cfg: Dict[str, Any],
        api_key: str,
        model: str,
        incremental: bool,
        cleanup_extra: bool,
        sort_keys: bool,
        progress: Progress,
) -> None:
    src_locale = cfg["source_locale"]
    targets = cfg["target_locales"]
    prompt_en_cfg = (cfg.get("prompt_en") or "").strip() or None

    src_path = group_file_name(group, src_locale)
    _, src_body = split_slang_json(src_path, load_json_obj(src_path))

    module_name = group.name if group.name != I18N_DIR else "i18n"

    for loc in targets:
        tgt_path = group_file_name(group, loc)
        tgt_meta, tgt_body = split_slang_json(tgt_path, load_json_obj(tgt_path))

        if cleanup_extra:
            tgt_body = {k: v for k, v in tgt_body.items() if k in src_body}

        need = {k: v for k, v in src_body.items() if k not in tgt_body} if incremental else dict(src_body)

        if not need:
            tgt_meta = dict(tgt_meta)
            tgt_meta.setdefault("@@locale", loc)
            save_json(tgt_path, tgt_meta, tgt_body, sort_keys=sort_keys)
            continue

        print(f"ğŸŒ {module_name}: {src_locale} â†’ {loc}  (+{len(need)} keys)")
        translated = translate_flat_dict(
            prompt_en=prompt_en_cfg,
            src_dict=need,
            src_lang=src_locale,
            tgt_locale=loc,
            model=model,
            api_key=api_key,
        )

        # âœ… æ–°å¢ï¼šç¿»è¯‘å®Œï¼ˆæœ¬æ¬¡ need å…¨é‡å®Œæˆï¼‰åï¼Œæ‰“å° source -> target
        # è¯´æ˜ï¼šä¸æŒ‰ chunkï¼›åªåœ¨ translate_flat_dict è¿”å›åæ‰“å°
        print(f"   ğŸ§¾ translated ({module_name} {src_locale} â†’ {loc}) : {len(translated)} keys")
        for k in need.keys():
            src_text = need.get(k, "")
            tgt_text = translated.get(k, "")
            # æŒ‰ä½ ç¤ºä¾‹ï¼šsource -> targetï¼ˆä¸é¢å¤–æ‰“å° keyï¼‰
            print(f"     {src_text} -> {tgt_text}")

        tgt_body.update(translated)
        tgt_meta = dict(tgt_meta)
        tgt_meta.setdefault("@@locale", loc)
        save_json(tgt_path, tgt_meta, tgt_body, sort_keys=sort_keys)

        progress.bump(len(translated))
        print(f"   ğŸ“ˆ {progress.done_keys}/{progress.total_keys} ({progress.percent()}%) {progress.eta_text()}")


def translate_all(i18n_dir: Path, cfg: Dict[str, Any], api_key: str, model: str, full: bool) -> None:
    incremental = not full
    cleanup_extra = bool(cfg["options"]["cleanup_extra_keys"])
    sort_keys = bool(cfg["options"]["sort_keys"])

    groups = get_active_groups(i18n_dir)
    targets = cfg["target_locales"]

    group_need: Dict[Path, int] = {}
    total_need = 0
    for g in groups:
        need_sum = 0
        for loc in targets:
            need_sum += _compute_need_for_one(g, cfg, loc, incremental=incremental, cleanup_extra=cleanup_extra)
        group_need[g] = need_sum
        total_need += need_sum

    prog = Progress(total_keys=total_need)
    print(f"ğŸ§® Total keys to translate: {total_need}ï¼ˆæ¨¡å¼={'å…¨é‡' if full else 'å¢é‡'}ï¼‰")
    if total_need == 0:
        print("âœ… æ— éœ€ç¿»è¯‘ï¼šæ‰€æœ‰è¯­è¨€æ–‡ä»¶å·²é½å…¨")
        return

    for g in groups:
        if group_need.get(g, 0) <= 0:
            continue
        translate_group(
            group=g,
            cfg=cfg,
            api_key=api_key,
            model=model,
            incremental=incremental,
            cleanup_extra=cleanup_extra,
            sort_keys=sort_keys,
            progress=prog,
        )


# =========================================================
# Doctor
# =========================================================
def doctor(cfg_path: Path, api_key: Optional[str]) -> None:
    ok = True

    if OpenAI is None:
        ok = False
        print("âŒ OpenAI SDK ä¸å¯ç”¨ï¼špipx: pipx inject box 'openai>=1.0.0'")
    else:
        print("âœ… OpenAI SDK OK")

    try:
        _require_yaml()
        print("âœ… PyYAML OK")
    except SystemExit as e:
        ok = False
        print(str(e).strip())

    i18n_dir = Path.cwd() / I18N_DIR
    if not i18n_dir.exists() or not i18n_dir.is_dir():
        ok = False
        print("âŒ æœªæ‰¾åˆ° i18n/ï¼ˆè¯·åœ¨é¡¹ç›®æ ¹ç›®å½•æ‰§è¡Œï¼‰")
    else:
        groups = get_active_groups(i18n_dir)
        if _has_any_subdir(i18n_dir):
            print(f"âœ… i18n/ OKï¼ˆæ£€æµ‹åˆ°å­ç›®å½•ï¼šä»…å¤„ç† {len(groups)} ä¸ªæ¨¡å—ç›®å½•ï¼›æ ¹ç›®å½•ä¸ä¼šç”Ÿæˆ/å¤„ç† jsonï¼‰")
        else:
            print("âœ… i18n/ OKï¼ˆæ— å­ç›®å½•ï¼šå¤„ç†æ ¹ç›®å½• jsonï¼‰")

    if not cfg_path.exists():
        ok = False
        print(f"âŒ æœªæ‰¾åˆ° {CONFIG_FILE}ï¼ˆè¯·å…ˆ slang_i18n initï¼‰")
    else:
        try:
            cfg = read_config(cfg_path)
            prompt_on = bool((cfg.get("prompt_en") or "").strip())
            normalize_on = bool(cfg["options"].get("normalize_filenames", True))
            print(
                f"âœ… {CONFIG_FILE} OK (source={cfg['source_locale']} targets={len(cfg['target_locales'])} "
                f"prompt_en={'ON' if prompt_on else 'OFF'} normalize_filenames={'ON' if normalize_on else 'OFF'})"
            )
        except Exception as e:
            ok = False
            print(f"âŒ {CONFIG_FILE} è§£æå¤±è´¥ï¼š{e}")

    ak = api_key or os.getenv("OPENAI_API_KEY")
    if not ak:
        print("âš ï¸ æœªæä¾› API Keyï¼š--api-key æˆ–ç¯å¢ƒå˜é‡ OPENAI_API_KEYï¼ˆç¿»è¯‘æ—¶éœ€è¦ï¼‰")
        print("   macOS/Linux: export OPENAI_API_KEY=\"sk-...\"")
        print("   Windows(PowerShell): setx OPENAI_API_KEY \"sk-...\"")
    else:
        print("âœ… API Key å·²é…ç½®ï¼ˆæ¥æºï¼šå‚æ•°æˆ–ç¯å¢ƒå˜é‡ï¼‰")

    if not ok:
        raise SystemExit(EXIT_BAD)
    print("âœ… doctor å®Œæˆ")


# =========================================================
# Interactive (pub_version style)
# =========================================================
def _read_choice(prompt: str, valid: Iterable[str]) -> str:
    valid_set = {v.lower() for v in valid}
    while True:
        s = input(prompt).strip().lower()
        if s in valid_set:
            return s
        if s in ("q", "quit", "exit"):
            return "0"
        print(f"è¯·è¾“å…¥ {' / '.join(sorted(valid_set))}ï¼ˆæˆ– q é€€å‡ºï¼‰")


def _ensure_api_key_interactive(passed: Optional[str]) -> Optional[str]:
    if passed:
        return passed
    env = os.getenv("OPENAI_API_KEY")
    if env:
        return env
    s = input("æœªæ£€æµ‹åˆ° OPENAI_API_KEYã€‚è¯·è¾“å…¥ apiKeyï¼ˆç›´æ¥å›è½¦å–æ¶ˆç¿»è¯‘ï¼‰: ").strip()
    return s or None


def choose_action_interactive() -> str:
    print("è¯·é€‰æ‹©æ“ä½œï¼š")
    print("1 - æ’åºï¼ˆsortï¼‰")
    print("2 - ç¿»è¯‘ï¼ˆé»˜è®¤å¢é‡ï¼Œå¯é€‰å…¨é‡ï¼‰")
    print("3 - æ£€æŸ¥å†—ä½™ï¼ˆcheckï¼‰")
    print("4 - åˆ é™¤å†—ä½™ï¼ˆcleanï¼‰")
    print("5 - doctor")
    print("6 - init")
    print("0 - é€€å‡º")
    choice = _read_choice("è¯·è¾“å…¥ 0 / 1 / 2 / 3 / 4 / 5 / 6ï¼ˆæˆ– q é€€å‡ºï¼‰: ", valid=["0", "1", "2", "3", "4", "5", "6"])
    if choice == "0":
        return "exit"
    return {
        "1": "sort",
        "2": "translate",
        "3": "check",
        "4": "clean",
        "5": "doctor",
        "6": "init",
    }[choice]


# =========================================================
# CLI
# =========================================================
def build_parser() -> argparse.ArgumentParser:
    p = argparse.ArgumentParser(
        prog="slang_i18n",
        description="Flutter slang i18nï¼ˆflat .i18n.jsonï¼‰æ’åº / å†—ä½™æ£€æŸ¥æ¸…ç† / å¢é‡ç¿»è¯‘ï¼ˆæ”¯æŒäº¤äº’ï¼‰",
    )
    p.add_argument(
        "action",
        nargs="?",
        choices=["init", "doctor", "sort", "translate", "check", "clean"],
        help="åŠ¨ä½œï¼ˆä¸å¡«åˆ™è¿›å…¥äº¤äº’èœå•ï¼‰",
    )
    p.add_argument("--api-key", default=None, help="OpenAI API keyï¼ˆä¹Ÿå¯ç”¨ç¯å¢ƒå˜é‡ OPENAI_API_KEYï¼‰")
    p.add_argument("--model", default=OpenAIModel.GPT_4O.value, help="æ¨¡å‹ï¼ˆé»˜è®¤ gpt-4oï¼‰")
    p.add_argument("--full", action="store_true", help="å…¨é‡ç¿»è¯‘ï¼ˆé»˜è®¤å¢é‡ç¿»è¯‘ï¼‰")
    p.add_argument("--yes", action="store_true", help="clean åˆ é™¤å†—ä½™æ—¶è·³è¿‡ç¡®è®¤")
    p.add_argument("--no-exitcode-3", action="store_true", help="check å‘ç°å†—ä½™æ—¶ä»è¿”å› 0ï¼ˆé»˜è®¤è¿”å› 3ï¼‰")
    return p


def main(argv: Optional[List[str]] = None) -> int:
    argv = sys.argv[1:] if argv is None else argv
    args = build_parser().parse_args(argv)

    cfg_path = Path.cwd() / CONFIG_FILE
    model = args.model

    action = args.action
    interactive = False
    if not action:
        interactive = True
        action = choose_action_interactive()
        if action == "exit":
            return EXIT_OK

    if action == "init":
        try:
            init_config(cfg_path)
            return EXIT_OK
        except Exception as e:
            print(str(e))
            return EXIT_BAD

    if action == "doctor":
        try:
            doctor(cfg_path, api_key=args.api_key)
            return EXIT_OK
        except SystemExit as e:
            return int(getattr(e, "code", EXIT_BAD))
        except Exception as e:
            print(str(e))
            return EXIT_BAD

    # below require cfg + i18n
    try:
        cfg = read_config_or_throw(cfg_path)
    except Exception as e:
        print(str(e))
        return EXIT_BAD

    try:
        i18n_dir = ensure_i18n_dir()
    except Exception as e:
        print(str(e))
        return EXIT_BAD

    try:
        ensure_all_language_files(i18n_dir, cfg)
    except Exception as e:
        print(f"âŒ è¡¥é½/è§„èŒƒåŒ–è¯­è¨€æ–‡ä»¶å¤±è´¥ï¼š{e}")
        return EXIT_BAD

    if action == "sort":
        try:
            sort_all_json(i18n_dir, sort_keys=bool(cfg["options"]["sort_keys"]))
            print("âœ… å·²å®Œæˆæ’åº")
            return EXIT_OK
        except Exception as e:
            print(f"âŒ æ’åºå¤±è´¥ï¼š{e}")
            return EXIT_FAIL

    if action == "check":
        try:
            items = collect_redundant(cfg, i18n_dir)
            report_redundant(items)
            if items and not args.no_exitcode_3:
                return EXIT_REDUNDANT_FOUND
            return EXIT_OK
        except Exception as e:
            print(f"âŒ å†—ä½™æ£€æŸ¥å¤±è´¥ï¼š{e}")
            return EXIT_FAIL

    if action == "clean":
        try:
            items = collect_redundant(cfg, i18n_dir)
            report_redundant(items)
            if not items:
                return EXIT_OK

            if not args.yes:
                ans = _read_choice("ç¡®è®¤åˆ é™¤ä»¥ä¸Šå†—ä½™ keyï¼Ÿè¯·è¾“å…¥ 1 åˆ é™¤ / 0 å–æ¶ˆ: ", valid=["0", "1"])
                if ans != "1":
                    print("ğŸ§Š å·²å–æ¶ˆåˆ é™¤")
                    return EXIT_OK

            delete_redundant(items, sort_keys=bool(cfg["options"]["sort_keys"]))
            print("âœ… å·²åˆ é™¤å†—ä½™ key")
            return EXIT_OK
        except Exception as e:
            print(f"âŒ åˆ é™¤å†—ä½™å¤±è´¥ï¼š{e}")
            return EXIT_FAIL

    if action == "translate":
        api_key = args.api_key or os.getenv("OPENAI_API_KEY")
        if not api_key and interactive:
            api_key = _ensure_api_key_interactive(None)

        if not api_key:
            print("âŒ æœªæä¾› apiKeyï¼ˆ--api-key æˆ– OPENAI_API_KEYï¼‰")
            return EXIT_BAD
        if OpenAI is None:
            print("âŒ OpenAI SDK ä¸å¯ç”¨ï¼špipx: pipx inject box 'openai>=1.0.0'")
            return EXIT_BAD

        full = bool(args.full)
        if interactive and args.action is None:
            print(f"ğŸ¤– å½“å‰æ¨¡å¼ï¼š{'å…¨é‡' if full else 'å¢é‡'}")
            m = _read_choice("é€‰æ‹©ç¿»è¯‘æ¨¡å¼ï¼š1 å¢é‡ / 2 å…¨é‡ / 0 å–æ¶ˆ: ", valid=["0", "1", "2"])
            if m == "0":
                print("ğŸ§Š å·²å–æ¶ˆç¿»è¯‘")
                return EXIT_OK
            full = m == "2"

        started = time.time()
        try:
            translate_all(i18n_dir, cfg, api_key=api_key, model=model, full=full)
        except TranslationError as e:
            print(f"âŒ TranslationError: {e}")
            return EXIT_FAIL
        except Exception as e:
            print(f"âŒ ç¿»è¯‘å¤±è´¥ï¼š{e}")
            return EXIT_FAIL

        cost = time.time() - started
        print(f"âœ… ç¿»è¯‘å®Œæˆï¼ˆ{cost:.1f}sï¼Œæ¨¡å¼={'å…¨é‡' if full else 'å¢é‡'}ï¼‰")

        # ç¿»è¯‘åå¯é€‰æ’åº
        try:
            if bool(cfg["options"]["sort_keys"]):
                sort_all_json(i18n_dir, sort_keys=True)
        except Exception:
            pass

        return EXIT_OK

    print("âŒ æœªçŸ¥ action")
    return EXIT_BAD


if __name__ == "__main__":
    try:
        raise SystemExit(main())
    except KeyboardInterrupt:
        # Ctrl+Cï¼šä¼˜é›…é€€å‡ºï¼Œä¸æ‰“å° traceback
        print("\nå·²å–æ¶ˆã€‚")
        raise SystemExit(130)  # 130 = SIGINT çš„æƒ¯ä¾‹é€€å‡ºç 
