#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
strings_i18n.py â€” iOS .strings å¤šèªè¨€ç®¡ç†å·¥å…·ï¼ˆRefactor: slang_i18n styleï¼‰

ç›®å½•çº¦å®šï¼ˆXcodeï¼‰ï¼š
- Base.lproj ä¸ en.lproj / zh-Hant.lproj ç­‰åŒçº§
- Base.lproj ä¸‹çš„ *.strings è§†ä¸º"éœ€è¦å¤„ç†çš„æ–‡ä»¶æ¸…å•"
- å…¶ä»–è¯­è¨€ç›®å½•ï¼š{code}.lproj
- æ¯ä¸ªè¯­è¨€ç›®å½•é‡Œåº”åŒ…å«ä¸ Base ç›¸åŒæ–‡ä»¶åçš„ *.strings

é…ç½®æ–‡ä»¶ï¼šstrings_i18n.yamlï¼ˆNEW schema, å¸¦æ³¨é‡Šæ¨¡æ¿ï¼‰
languages.jsonï¼šè¯­è¨€æ¸…å•ï¼ˆç”¨äº sync & init ç”Ÿæˆ target_locales ç­‰ï¼‰
ç¿»è¯‘ï¼šä½¿ç”¨ ./comm/translate.py ä¸­çš„ translate_flat_dictï¼ˆflat dict ç¿»è¯‘ï¼‰

åŠŸèƒ½ï¼ˆactionsï¼‰ï¼š
- init               ç”Ÿæˆ strings_i18n.yamlï¼ˆè‹¥å­˜åœ¨åˆ™æ ¡éªŒä¸è¦†ç›–ï¼‰
- doctor             æ£€æŸ¥ä¾èµ– / ç›®å½•ç»“æ„ / é…ç½® / API Key
- scan               æ‰«æ Base.lproj çš„ *.strings æ–‡ä»¶
- sync               æŒ‰ languages.json è¡¥é½ {code}.lproj + *.strings
- sort               å¯¹æ‰€æœ‰è¯­è¨€çš„ *.strings åšæ’åºï¼ˆæŒ‰ Base key é¡ºåº + prefix åˆ†ç»„ + ä¿ç•™æ³¨é‡Š/ç©ºè¡Œï¼‰
- dupcheck           é‡å¤ key æ£€æŸ¥ï¼ˆå…ˆæ±‡æ€»æ˜¾ç¤ºï¼‰
- dedupe             åˆ é™¤é‡å¤ keyï¼ˆå…ˆæ±‡æ€»æ˜¾ç¤ºï¼Œæœ€åç¡®è®¤ä¸€æ¬¡ï¼›--keep first/lastï¼›--yes è·³è¿‡ç¡®è®¤ï¼‰
- check              å†—ä½™ key æ£€æŸ¥ï¼ˆBase æ²¡æœ‰ã€ç›®æ ‡æœ‰ï¼‰
- clean              åˆ é™¤å†—ä½™ keyï¼ˆå…ˆæ±‡æ€»æ˜¾ç¤ºï¼Œæœ€åç¡®è®¤ä¸€æ¬¡ï¼›--yes è·³è¿‡ç¡®è®¤ï¼‰
- translate-core     å¢é‡ç¿»è¯‘ï¼šbase_locale â†’ core_localesï¼ˆæºï¼šBase.lproj/*.stringsï¼‰
- translate-target   å¢é‡ç¿»è¯‘ï¼šsource_locale â†’ target_localesï¼ˆæºï¼š{source_code}.lproj/*.stringsï¼‰

Exit codes:
- 0 æˆåŠŸ
- 1 æ‰§è¡Œå¤±è´¥
- 2 ç¯å¢ƒ/é…ç½®é”™è¯¯
- 3 check/dupcheck å‘ç°é—®é¢˜ï¼ˆé»˜è®¤è¿”å› 3ï¼Œä¾¿äº CIï¼‰
"""

from __future__ import annotations

import argparse
import json
import os
import re
import sys
import time
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, Iterable, List, Optional, Set, Tuple

try:
    from openai import OpenAI  # noqa: F401
except Exception:
    OpenAI = None  # type: ignore

# âœ… ä½¿ç”¨åŒç›®å½•ä¸‹ comm/translate æ¨¡å—ï¼ˆä¸ slang_i18n å¯¹é½ï¼‰
from .comm.translate import OpenAIModel, TranslationError, translate_flat_dict  # type: ignore


# =========================================================
# BOX_TOOL (å¯¹é½ slang_i18n)
# =========================================================
BOX_TOOL = {
    "id": "ios.strings_i18n",
    "name": "strings_i18n",
    "category": "ios",
    "summary": "iOS/Xcode .strings å¤šè¯­è¨€ï¼šæ‰«æ/åŒæ­¥/æ’åº/é‡å¤ä¸å†—ä½™æ¸…ç†/å¢é‡ç¿»è¯‘ï¼ˆæ”¯æŒäº¤äº’ï¼‰",
    "usage": [
        "strings_i18n",
        "strings_i18n options",
        "strings_i18n init",
        "strings_i18n doctor",
        "strings_i18n scan",
        "strings_i18n sync",
        "strings_i18n sort",
        "strings_i18n dupcheck",
        "strings_i18n dedupe --yes --keep first",
        "strings_i18n check",
        "strings_i18n clean --yes",
        "strings_i18n translate-core --api-key $OPENAI_API_KEY",
        "strings_i18n translate-target --api-key $OPENAI_API_KEY",
        "strings_i18n gen-l10n",
    ],
    "options": [
        {"flag": "--config", "desc": "é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ strings_i18n.yamlï¼‰"},
        {"flag": "--languages", "desc": "languages.json è·¯å¾„ï¼ˆé»˜è®¤ languages.jsonï¼‰"},
        {"flag": "--api-key", "desc": "OpenAI API keyï¼ˆä¹Ÿå¯ç”¨ç¯å¢ƒå˜é‡ OPENAI_API_KEYï¼‰"},
        {"flag": "--model", "desc": "æ¨¡å‹ï¼ˆå‘½ä»¤è¡Œä¼˜å…ˆï¼›ä¸ä¼ åˆ™ç”¨é…ç½® openAIModelï¼›é»˜è®¤ gpt-4oï¼‰"},
        {"flag": "--full", "desc": "å…¨é‡ç¿»è¯‘ï¼ˆé»˜è®¤å¢é‡ï¼šåªè¡¥ç¼ºå¤±/ç©ºå€¼ keyï¼‰"},
        {"flag": "--yes", "desc": "clean/dedupe åˆ é™¤æ—¶è·³è¿‡ç¡®è®¤"},
        {"flag": "--keep", "desc": "dedupe ä¿ç•™ç­–ç•¥ï¼šfirst/lastï¼ˆé»˜è®¤ firstï¼‰"},
        {"flag": "--no-exitcode-3", "desc": "check/dupcheck å‘ç°é—®é¢˜æ—¶ä»è¿”å› 0ï¼ˆé»˜è®¤è¿”å› 3ï¼‰"},
        {"flag": "--dry-run", "desc": "é¢„è§ˆæ¨¡å¼ï¼ˆä¸å†™å…¥æ–‡ä»¶ï¼‰"},
    ],
    "dependencies": [
        "PyYAML>=6.0",
        "openai>=1.0.0",
    ],
}


# =========================================================
# Constants / Exit codes
# =========================================================
CONFIG_FILE = "strings_i18n.yaml"
LANG_FILE = "languages.json"

EXIT_OK = 0
EXIT_FAIL = 1
EXIT_BAD = 2
EXIT_FOUND = 3

ALLOWED_OPENAI_MODELS = (
    "gpt-4o",
    "gpt-4o-mini",
    "gpt-4.1",
    "gpt-4.1-mini",
)


# =========================================================
# Lazy import for PyYAML
# =========================================================
def _require_yaml():
    try:
        import yaml  # type: ignore
        return yaml
    except Exception:
        raise SystemExit(
            "âŒ ç¼ºå°‘ä¾èµ– PyYAMLï¼ˆimport yaml å¤±è´¥ï¼‰\n"
            "ä¿®å¤æ–¹å¼ï¼š\n"
            "1) pipx å®‰è£…ï¼špipx inject box pyyaml\n"
            "2) æˆ–åœ¨ pyproject.toml dependencies åŠ å…¥ PyYAML>=6.0 åé‡æ–°å‘å¸ƒ/å®‰è£…\n"
        )


# =========================================================
# Config schema (NEW)
# =========================================================
def _schema_error(msg: str) -> ValueError:
    return ValueError(
        "strings_i18n.yaml æ ¼å¼é”™è¯¯ï¼š\n"
        f"- {msg}\n\n"
        "æœŸæœ›ç»“æ„ï¼ˆæ–° schemaï¼‰ç¤ºä¾‹ï¼š\n"
        "openAIModel: gpt-4o\n"
        "lang_root: ./TimeTrails/TimeTrails/SupportFiles/\n"
        "base_folder: Base.lproj\n"
        "languages: ./languages.json\n"
        "base_locale:\n"
        "  - code: zh-Hans\n"
        "    name_en: Simplified Chinese\n"
        "source_locale:\n"
        "  - code: en\n"
        "    name_en: English\n"
        "core_locales:\n"
        "  - code: zh-Hant\n"
        "    name_en: Traditional Chinese\n"
        "target_locales:\n"
        "  - code: de\n"
        "    name_en: German\n"
        "prompts:\n"
        "  default_en: |\n"
        "    Translate UI strings naturally.\n"
        "  by_locale_en:\n"
        "    zh-Hant: |\n"
        "      Use Taiwan Traditional Chinese UI style.\n"
        "options:\n"
        "  sort_keys: true\n"
        "  cleanup_extra_keys: true\n"
        "  incremental_translate: true\n"
    )


def _need_nonempty_str(obj: Dict[str, Any], key: str, path: str) -> str:
    v = obj.get(key)
    if not isinstance(v, str) or not v.strip():
        raise _schema_error(f"{path}.{key} å¿…é¡»æ˜¯éç©ºå­—ç¬¦ä¸²")
    return v.strip()


def _need_bool(obj: Dict[str, Any], key: str, path: str) -> bool:
    v = obj.get(key)
    if not isinstance(v, bool):
        raise _schema_error(f"{path}.{key} å¿…é¡»æ˜¯ boolï¼ˆtrue/falseï¼‰")
    return v


def _need_openai_model(cfg: Dict[str, Any]) -> str:
    v = cfg.get("openAIModel", OpenAIModel.GPT_4O.value)
    if v is None:
        v = OpenAIModel.GPT_4O.value
    if not isinstance(v, str) or not v.strip():
        raise _schema_error("openAIModel å¿…é¡»æ˜¯éç©ºå­—ç¬¦ä¸²")
    v = v.strip()
    if v not in set(ALLOWED_OPENAI_MODELS):
        raise _schema_error(f"openAIModel ä¸åˆæ³•ï¼š{v!r}ï¼Œå¯é€‰ï¼š{', '.join(ALLOWED_OPENAI_MODELS)}")
    return v


def _parse_locale_list(cfg: Dict[str, Any], key: str) -> List[Dict[str, str]]:
    raw = cfg.get(key)
    if not isinstance(raw, list) or not raw:
        raise _schema_error(f"{key} å¿…é¡»æ˜¯éç©ºæ•°ç»„ï¼ˆæ¯é¡¹ä¸º {{code,name_en}}ï¼‰")
    out: List[Dict[str, str]] = []
    seen: Set[str] = set()
    for i, it in enumerate(raw):
        if not isinstance(it, dict):
            raise _schema_error(f"{key}[{i}] å¿…é¡»æ˜¯ object/mapï¼ˆåŒ…å« code / name_enï¼‰")
        code = _need_nonempty_str(it, "code", f"{key}[{i}]")
        name_en = _need_nonempty_str(it, "name_en", f"{key}[{i}]")
        if code in seen:
            raise _schema_error(f"{key}[{i}].code é‡å¤ï¼š{code}")
        seen.add(code)
        out.append({"code": code, "name_en": name_en})
    return out


def validate_config(cfg: Any) -> Dict[str, Any]:
    if not isinstance(cfg, dict):
        raise _schema_error("æ ¹èŠ‚ç‚¹å¿…é¡»æ˜¯ YAML object/map")

    openai_model = _need_openai_model(cfg)

    lang_root = cfg.get("lang_root")
    base_folder = cfg.get("base_folder")
    languages_path = cfg.get("languages", "./languages.json")

    if not isinstance(lang_root, str) or not lang_root.strip():
        raise _schema_error("lang_root å¿…é¡»æ˜¯éç©ºå­—ç¬¦ä¸²")
    if not isinstance(base_folder, str) or not base_folder.strip():
        raise _schema_error("base_folder å¿…é¡»æ˜¯éç©ºå­—ç¬¦ä¸²ï¼ˆé€šå¸¸ Base.lprojï¼‰")
    if not isinstance(languages_path, str) or not languages_path.strip():
        raise _schema_error("languages å¿…é¡»æ˜¯éç©ºå­—ç¬¦ä¸²ï¼ˆlanguages.json è·¯å¾„ï¼‰")

    prompts = cfg.get("prompts") or {}
    if not isinstance(prompts, dict):
        raise _schema_error("prompts å¿…é¡»æ˜¯ object/mapï¼ˆå¯çœç•¥ï¼‰")
    default_en = prompts.get("default_en", "")
    if default_en is None:
        default_en = ""
    if not isinstance(default_en, str):
        raise _schema_error("prompts.default_en å¿…é¡»æ˜¯å­—ç¬¦ä¸²ï¼ˆå¯ä¸ºç©ºï¼‰")
    by_locale_en = prompts.get("by_locale_en", {}) or {}
    if not isinstance(by_locale_en, dict):
        raise _schema_error("prompts.by_locale_en å¿…é¡»æ˜¯ object/mapï¼ˆå¯çœç•¥ï¼‰")
    by_locale_en2: Dict[str, str] = {}
    for k, v in by_locale_en.items():
        if not isinstance(k, str) or not k.strip():
            raise _schema_error("prompts.by_locale_en çš„ key å¿…é¡»æ˜¯éç©ºå­—ç¬¦ä¸²ï¼ˆlocale codeï¼‰")
        if not isinstance(v, str):
            raise _schema_error(f"prompts.by_locale_en[{k!r}] å¿…é¡»æ˜¯å­—ç¬¦ä¸²")
        by_locale_en2[k.strip()] = v

    opts = cfg.get("options")
    if not isinstance(opts, dict):
        raise _schema_error("options å¿…é¡»æ˜¯ object/map")

    normalize_filenames = opts.get("normalize_filenames", True)
    if not isinstance(normalize_filenames, bool):
        raise _schema_error("options.normalize_filenames å¿…é¡»æ˜¯ boolï¼ˆtrue/falseï¼‰")

    base_locale = _parse_locale_list(cfg, "base_locale")
    source_locale = _parse_locale_list(cfg, "source_locale")
    core_locales = _parse_locale_list(cfg, "core_locales")
    target_locales = _parse_locale_list(cfg, "target_locales")

    return {
        "openAIModel": openai_model,
        "lang_root": lang_root.strip(),
        "base_folder": base_folder.strip(),
        "languages": languages_path.strip(),
        "base_locale": base_locale,
        "source_locale": source_locale,
        "core_locales": core_locales,
        "target_locales": target_locales,
        "prompts": {"default_en": default_en, "by_locale_en": by_locale_en2},
        "options": {
            "sort_keys": _need_bool(opts, "sort_keys", "options"),
            "cleanup_extra_keys": _need_bool(opts, "cleanup_extra_keys", "options"),
            "incremental_translate": _need_bool(opts, "incremental_translate", "options"),
            "normalize_filenames": normalize_filenames,
        },
    }


def read_config(path: Path) -> Dict[str, Any]:
    yaml = _require_yaml()
    raw = yaml.safe_load(path.read_text(encoding="utf-8"))
    return validate_config(raw)


def read_config_or_throw(path: Path) -> Dict[str, Any]:
    if not path.exists():
        raise FileNotFoundError(f"âŒ æœªæ‰¾åˆ° {CONFIG_FILE}ï¼ˆè¯·å…ˆ strings_i18n initï¼‰")
    return read_config(path)


def _config_template_text() -> str:
    # æ¨¡æ¿æ–‡æœ¬ï¼šä¸ºäº†ä¿ç•™æ³¨é‡Šï¼ˆå¯¹é½ slang çš„"æ¨¡æ¿æ–‡æœ¬ init"æ€è·¯ï¼‰
    return """# strings_i18n.yaml
# iOS/Xcode .strings å¤šè¯­è¨€é…ç½®ï¼ˆNEW schemaï¼‰
#
# ç›®å½•çº¦å®šï¼ˆåœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œï¼‰ï¼š
# - {lang_root}/{base_folder} å¿…é¡»å­˜åœ¨ï¼ˆé€šå¸¸ Base.lprojï¼‰
# - Base.lproj ä¸å…¶å®ƒ *.lproj åŒçº§ï¼ˆXcode çº¦å®šï¼‰
# - éœ€è¦å¤„ç†çš„æ–‡ä»¶ï¼šæ‰«æ Base.lproj ä¸‹çš„ *.strings
#
# languages.jsonï¼šç”¨äº sync è¡¥é½è¯­è¨€ç›®å½•/æ–‡ä»¶ã€ä»¥åŠ init ç”Ÿæˆ target_locales

# OpenAI æ¨¡å‹ï¼ˆé»˜è®¤ gpt-4oï¼‰
# å¯é€‰å€¼ï¼ˆæšä¸¾ï¼‰ï¼š
# - gpt-4o
# - gpt-4o-mini
# - gpt-4.1
# - gpt-4.1-mini
openAIModel: gpt-4o

# è¯­è¨€ç›®å½•æ ¹è·¯å¾„ï¼ˆç›¸å¯¹é¡¹ç›®æ ¹ç›®å½•ï¼‰
lang_root: ./TimeTrails/TimeTrails/SupportFiles/

# Base ç›®å½•åï¼ˆé€šå¸¸ Base.lprojï¼‰
base_folder: Base.lproj

# languages.json è·¯å¾„ï¼ˆç›¸å¯¹é¡¹ç›®æ ¹ç›®å½•ï¼‰
languages: ./languages.json

# åŸºç¡€è¯­è¨€ï¼ˆç”¨äº translate-coreï¼šBase.lproj -> core_localesï¼‰
base_locale:
  - code: zh-Hans
    name_en: Simplified Chinese

# æºè¯­è¨€ï¼ˆç”¨äº translate-targetï¼š{source}.lproj -> target_localesï¼‰
source_locale:
  - code: en
    name_en: English

# æ ¸å¿ƒè¯­è¨€ï¼ˆå¸¸é©»ä¼˜å…ˆç¿»è¯‘ï¼‰
core_locales:
  - code: zh-Hant
    name_en: Traditional Chinese
  - code: en
    name_en: English
  - code: ja
    name_en: Japanese
  - code: ko
    name_en: Korean

# ç›®æ ‡è¯­è¨€ï¼ˆé€šå¸¸ç”± init ä» languages.json è‡ªåŠ¨ç”Ÿæˆï¼Œå¹¶æ’é™¤ core_localesï¼‰
target_locales:
  - code: de
    name_en: German
  - code: es
    name_en: Spanish

# æç¤ºè¯ï¼ˆè‹±æ–‡ï¼‰ï¼šæ”¯æŒ default + by_locale "è¿½åŠ "
prompts:
  default_en: |
    Translate UI strings naturally for a mobile app.
    Be concise, clear, and consistent.
    Preserve placeholders and formatting tokens unchanged.

  by_locale_en:
    zh-Hant: |
      Use Taiwan-style Traditional Chinese for UI.
      Prefer common Taiwan wording (e.g., "å¸³è™Ÿ", "ç™»å…¥", "è«‹ç¨å¾Œå†è©¦").

    ja: |
      Use polite and concise Japanese UI tone suitable for mobile apps.

    ko: |
      Use natural Korean UI style suitable for mobile apps.

# é€‰é¡¹ï¼ˆå¸ƒå°”å€¼ï¼‰
options:
  # sort ä¼šæŒ‰ Base key é¡ºåº + prefix åˆ†ç»„è¾“å‡ºï¼›æ­¤å¼€å…³ç”¨äºæœªæ¥æ‰©å±•ï¼ˆå½“å‰é»˜è®¤ trueï¼‰
  sort_keys: true

  # translate æ—¶æ˜¯å¦å…ˆè¿‡æ»¤ç›®æ ‡æ–‡ä»¶é‡Œçš„å†—ä½™ keyï¼ˆé¿å…å¹½çµ key æ‰©æ•£ï¼‰
  cleanup_extra_keys: true

  # æ˜¯å¦å¢é‡ç¿»è¯‘ï¼štrue=åªè¡¥ç¼ºå¤±/ç©ºå€¼ï¼›false=å…¨é‡è¦†ç›–ï¼ˆç­‰ä»· --fullï¼‰
  incremental_translate: true

  # é¢„ç•™ï¼šæ˜¯å¦è§„èŒƒåŒ–æ–‡ä»¶åï¼ˆiOS .strings é€šå¸¸ä¸éœ€è¦é‡å‘½åï¼Œä¿æŒ false/true éƒ½ä¸å½±å“æ ¸å¿ƒåŠŸèƒ½ï¼‰
  normalize_filenames: true
"""


def init_config(cfg_path: Path, project_root: Path, languages_path: Path) -> None:
    _require_yaml()  # ensure deps

    if cfg_path.exists():
        _ = read_config(cfg_path)  # å­˜åœ¨å°±æ ¡éªŒï¼Œä¸è¦†ç›–
        print(f"âœ… {CONFIG_FILE} å·²å­˜åœ¨ä¸”æ ¼å¼æ­£ç¡®ï¼ˆä¸ä¼šè¦†ç›–ï¼‰")
        return

    # ç”Ÿæˆæ¨¡æ¿
    cfg_path.write_text(_config_template_text(), encoding="utf-8")
    print(f"ğŸ“ å·²ç”Ÿæˆ {CONFIG_FILE}ï¼ˆæ–° schemaï¼Œå«è¯¦ç»†æ³¨é‡Šï¼‰")

    # å¦‚æœ languages.json å­˜åœ¨ï¼šå°½åŠ›ç”Ÿæˆ/æ›´æ–° target_localesï¼ˆä¸è¦†ç›–æ•´ä¸ª yamlï¼Œåªç»™æç¤ºï¼‰
    if not languages_path.exists():
        print(f"âš ï¸ æœªæ‰¾åˆ° {languages_path}ï¼Œæ— æ³•è‡ªåŠ¨ä» languages.json è¡¥é½ target_localesï¼ˆå¯ç¨åå†è¿è¡Œ initï¼‰")
        return

    print("â„¹ï¸ å·²ç”Ÿæˆé…ç½®æ¨¡æ¿ã€‚å»ºè®®ä¸‹ä¸€æ­¥ï¼šstrings_i18n doctor / scan / sync")


# =========================================================
# languages.json helpers
# =========================================================
def load_languages_json(path: Path) -> List[Dict[str, str]]:
    if not path.exists():
        raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ° languages.jsonï¼š{path}")

    data = json.loads(path.read_text(encoding="utf-8"))
    if not isinstance(data, list):
        raise ValueError("âŒ languages.json é¡¶å±‚å¿…é¡»æ˜¯ list")

    out: List[Dict[str, str]] = []
    seen: Set[str] = set()
    for it in data:
        if not isinstance(it, dict):
            continue
        code = str(it.get("code", "")).strip()
        name_en = str(it.get("name_en", "")).strip()
        if not code or not name_en:
            continue
        if code.lower() in ("base", "base.lproj"):
            continue
        if code in seen:
            continue
        seen.add(code)
        out.append({"code": code, "name_en": name_en})

    out.sort(key=lambda x: x["code"].lower())
    return out


def code_to_lproj(code: str) -> str:
    return code if code.endswith(".lproj") else f"{code}.lproj"


# =========================================================
# iOS/Xcode scanning helpers
# =========================================================
def project_paths(project_root: Path, cfg: Dict[str, Any]) -> Tuple[Path, Path]:
    lang_root = (project_root / Path(cfg["lang_root"])).resolve()
    base_dir = (lang_root / Path(cfg["base_folder"])).resolve()
    return lang_root, base_dir


def scan_base_strings(base_dir: Path) -> List[Path]:
    if not base_dir.exists() or not base_dir.is_dir():
        raise FileNotFoundError(f"âŒ Base ç›®å½•ä¸å­˜åœ¨ï¼š{base_dir}")
    files = [p for p in base_dir.iterdir() if p.is_file() and p.suffix == ".strings"]
    files.sort(key=lambda p: p.name.lower())
    if not files:
        raise FileNotFoundError(f"âŒ Base ç›®å½•ä¸‹æœªæ‰¾åˆ°ä»»ä½• *.stringsï¼š{base_dir}")
    return files


def ensure_dir(p: Path, dry: bool) -> bool:
    if p.exists():
        if not p.is_dir():
            raise FileExistsError(f"è·¯å¾„å­˜åœ¨ä½†ä¸æ˜¯ç›®å½•ï¼š{p}")
        return False
    if not dry:
        p.mkdir(parents=True, exist_ok=True)
    return True


def ensure_file(p: Path, dry: bool) -> bool:
    if p.exists():
        if not p.is_file():
            raise FileExistsError(f"è·¯å¾„å­˜åœ¨ä½†ä¸æ˜¯æ–‡ä»¶ï¼š{p}")
        return False
    if not dry:
        p.parent.mkdir(parents=True, exist_ok=True)
        p.write_text("", encoding="utf-8")
    return True


def sync_language_dirs_and_files(
        *,
        lang_root_dir: Path,
        base_files: List[Path],
        locale_codes: List[str],
        dry: bool,
) -> Dict[str, Any]:
    created_dirs: List[str] = []
    created_files: List[str] = []
    existing_dirs = 0
    existing_files = 0

    for code in locale_codes:
        lproj_dir = lang_root_dir / code_to_lproj(code)
        if ensure_dir(lproj_dir, dry):
            created_dirs.append(str(lproj_dir))
        else:
            existing_dirs += 1

        for bf in base_files:
            target = lproj_dir / bf.name
            if ensure_file(target, dry):
                created_files.append(str(target))
            else:
                existing_files += 1

    return {
        "created_dirs": created_dirs,
        "created_files": created_files,
        "existing_dirs": existing_dirs,
        "existing_files": existing_files,
    }


# =========================================================
# .strings parse / sort (ä¿ç•™æ³¨é‡Š/ç©ºè¡Œ)
# =========================================================
ENTRY_RE = re.compile(
    r'^\s*"([^"\\]*(?:\\.[^"\\]*)*)"\s*=\s*"([^"\\]*(?:\\.[^"\\]*)*)"\s*;\s*(?://.*)?$'
)
COMMENT_START_RE = re.compile(r"^\s*/\*")
COMMENT_END_RE = re.compile(r"\*/\s*$")
LINE_COMMENT_RE = re.compile(r"^\s*//")


@dataclass
class StringsEntry:
    key: str
    value: str
    comments: List[str]
    raw_before: List[str]


@dataclass
class ParsedStrings:
    header: List[str]
    entries: List[StringsEntry]
    tail: List[str]


def parse_strings_file(path: Path) -> ParsedStrings:
    lines = path.read_text(encoding="utf-8", errors="replace").splitlines(keepends=True)
    header: List[str] = []
    tail: List[str] = []
    entries: List[StringsEntry] = []
    pending_comments: List[str] = []
    pending_misc: List[str] = []
    in_comment = False
    seen_entry = False

    for line in lines:
        if in_comment:
            pending_comments.append(line)
            if COMMENT_END_RE.search(line):
                in_comment = False
            continue

        if COMMENT_START_RE.search(line):
            in_comment = True
            pending_comments.append(line)
            if COMMENT_END_RE.search(line):
                in_comment = False
            continue

        if LINE_COMMENT_RE.search(line):
            pending_comments.append(line)
            continue

        m = ENTRY_RE.match(line)
        if m:
            seen_entry = True
            entries.append(
                StringsEntry(
                    key=m.group(1),
                    value=m.group(2),
                    comments=pending_comments,
                    raw_before=pending_misc,
                )
            )
            pending_comments = []
            pending_misc = []
            continue

        if not seen_entry:
            header.append(line)
        else:
            pending_misc.append(line)

    if not seen_entry:
        header = pending_comments + pending_misc
        pending_comments, pending_misc = [], []

    if pending_comments or pending_misc:
        tail.extend(pending_comments)
        tail.extend(pending_misc)

    return ParsedStrings(header, entries, tail)


def prefix_of_key(key: str) -> str:
    return key.split(".", 1)[0] if "." in key else key


def _group_entries_by_prefix(entries: List[StringsEntry]) -> Dict[str, List[StringsEntry]]:
    grouped: Dict[str, List[StringsEntry]] = {}
    for e in entries:
        pref = prefix_of_key(e.key)
        grouped.setdefault(pref, []).append(e)
    return grouped


def sort_base_file_inplace(base_file: Path, dry: bool) -> bool:
    """å¯¹ Base.lproj ä¸‹çš„å•ä¸ª *.strings åšï¼šæŒ‰å‰ç¼€åˆ†ç»„ã€ç»„åæ’åºã€ç»„å†…æŒ‰ key æ’åºï¼›ä¿ç•™æ³¨é‡Š/ç©ºè¡Œã€‚"""
    parsed = parse_strings_file(base_file)
    if not parsed.entries:
        return False

    # Baseï¼šéœ€è¦â€œæŒ‰å‰ç¼€åˆ†ç»„ + ç»„é—´ç•™ç©ºè¡Œâ€ã€‚
    grouped = _group_entries_by_prefix(parsed.entries)
    prefix_order = sorted(grouped.keys(), key=str.lower)

    out: List[str] = parsed.header[:]
    first_group = True
    for pref in prefix_order:
        if not first_group:
            # ç»„é—´é—´éš”ï¼šä¸€è¡Œç©ºè¡Œï¼ˆä¸ä¹‹å‰ç›®æ ‡è¯­è¨€åˆ†ç»„çš„è§†è§‰ä¸€è‡´ï¼Œä½†åªç”¨äº Baseï¼‰
            out.extend(["\n"])
        first_group = False

        group_entries = sorted(grouped[pref], key=lambda e: e.key.lower())
        for e in group_entries:
            out.extend(format_entry(e))

    if parsed.tail:
        if out and not out[-1].endswith("\n"):
            out.append("\n")
        out.extend(parsed.tail)

    new_content = "".join(out)
    old_content = base_file.read_text(encoding="utf-8", errors="replace")
    changed = new_content != old_content
    if changed and not dry:
        base_file.write_text(new_content, encoding="utf-8")
    return changed


def format_entry(e: StringsEntry) -> List[str]:
    # çº¦å®šï¼šæ³¨é‡Šå¿…é¡»è´´åœ¨ key ä¸Šæ–¹ã€‚
    # raw_before é€šå¸¸æ˜¯ç©ºè¡Œ/æ‚é¡¹ï¼Œåº”è¯¥æ”¾åœ¨â€œæ³¨é‡Šå—ä¹‹å‰â€ï¼Œé¿å…å‡ºç°â€œæ³¨é‡Šåœ¨ä¸Šï¼Œä½† key åœ¨æ›´ä¸‹é¢â€çš„è§†è§‰æ–­è£‚ã€‚
    return e.raw_before + e.comments + [f'"{e.key}" = "{e.value}";\n']


def sort_one_file(base_file: Path, target_file: Path, dry: bool) -> bool:
    base = parse_strings_file(base_file)
    tgt = parse_strings_file(target_file)

    base_order = [e.key for e in base.entries]
    base_set = set(base_order)

    tgt_multi: Dict[str, List[StringsEntry]] = {}
    for e in tgt.entries:
        tgt_multi.setdefault(e.key, []).append(e)

    # 1) in-base: follow base key order (keep duplicates as-is, just relocate)
    in_base: List[StringsEntry] = []
    for k in base_order:
        if k in tgt_multi:
            in_base.extend(tgt_multi[k])

    # 2) extras: keys not in base, sorted by key
    extras: List[StringsEntry] = []
    extra_keys = sorted((k for k in tgt_multi.keys() if k not in base_set), key=str.lower)
    for k in extra_keys:
        extras.extend(tgt_multi[k])

    # 3) ç›®æ ‡è¯­è¨€ï¼šä¸éœ€è¦å‰ç¼€åˆ†ç»„ã€ä¸éœ€è¦ç»„é—´é—´éš”ã€‚
    #    åªæŒ‰ Base key é¡ºåºè¾“å‡ºï¼ˆåŒ…å«é‡å¤ key çš„â€œåŸæ ·æ¬è¿â€ï¼‰ï¼Œæœ€åè¿½åŠ  extrasï¼ˆæŒ‰ key æ’åºï¼‰ã€‚
    out: List[str] = tgt.header[:]
    for e in (in_base + extras):
        # ç›®æ ‡è¯­è¨€ï¼šä¸åšåˆ†ç»„/ä¸åŠ é—´éš”ï¼Œä¹Ÿä¸ä¿ç•™ raw_before çš„ç©ºè¡Œå™ªå£°ï¼›
        # ä½†ä¿ç•™â€œç´§è´´åœ¨ key ä¸Šæ–¹â€çš„æ³¨é‡Šã€‚
        out.extend(e.comments)
        out.append(f'"{e.key}" = "{e.value}";\n')

    if tgt.tail:
        if out and not out[-1].endswith("\n"):
            out.append("\n")
        out.extend(tgt.tail)

    new_content = "".join(out)
    old_content = target_file.read_text(encoding="utf-8", errors="replace")

    changed = new_content != old_content
    if changed and not dry:
        target_file.write_text(new_content, encoding="utf-8")
    return changed


def sort_all(
        *,
        lang_root_dir: Path,
        base_dir: Path,
        base_files: List[Path],
        locale_codes: List[str],
        dry: bool,
) -> Dict[str, int]:
    # 0) å…ˆæŠŠ Base.lproj è‡ªå·±çš„æ–‡ä»¶æ’åºå¥½ï¼ˆæŒ‰å‰ç¼€åˆ†ç»„ + ç»„å/ç»„å†…æ’åºï¼‰ï¼Œä¸ºåç»­è¯­è¨€æä¾›ç¨³å®šé¡ºåºã€‚
    base_changed = 0
    for bf in base_files:
        if sort_base_file_inplace(base_dir / bf.name, dry):
            base_changed += 1

    total = 0
    changed = 0
    missing = 0

    for code in locale_codes:
        lproj = lang_root_dir / code_to_lproj(code)
        for bf in base_files:
            total += 1
            target = lproj / bf.name
            if not target.exists():
                missing += 1
                continue
            if sort_one_file(base_dir / bf.name, target, dry):
                changed += 1

    return {"total": total, "changed": changed, "missing": missing, "base_changed": base_changed}


# =========================================================
# Duplicate / Redundant helpers (batch confirm once)
# =========================================================
def find_duplicates(entries: List[StringsEntry]) -> Dict[str, List[int]]:
    idx: Dict[str, List[int]] = {}
    for i, e in enumerate(entries):
        idx.setdefault(e.key, []).append(i)
    return {k: v for k, v in idx.items() if len(v) > 1}


def filter_entries_with_carry(parsed: ParsedStrings, keep_predicate) -> ParsedStrings:
    new_entries: List[StringsEntry] = []
    carry: List[str] = []

    for e in parsed.entries:
        keep = keep_predicate(e)
        if keep:
            if carry:
                e = StringsEntry(
                    key=e.key,
                    value=e.value,
                    comments=carry + e.comments,
                    raw_before=e.raw_before,
                )
                carry = []
            new_entries.append(e)
        else:
            carry.extend(e.comments)
            carry.extend(e.raw_before)

    new_tail = parsed.tail[:]
    if carry:
        new_tail = carry + new_tail
    return ParsedStrings(parsed.header[:], new_entries, new_tail)


def write_parsed_strings(path: Path, parsed: ParsedStrings, dry: bool) -> bool:
    out: List[str] = []
    out.extend(parsed.header)
    for e in parsed.entries:
        out.extend(format_entry(e))
    out.extend(parsed.tail)

    new_content = "".join(out)
    old_content = path.read_text(encoding="utf-8", errors="replace")
    changed = new_content != old_content
    if changed and not dry:
        path.write_text(new_content, encoding="utf-8")
    return changed


def collect_existing_target_files(
        *,
        lang_root_dir: Path,
        base_files: List[Path],
        locale_codes: List[str],
) -> List[Path]:
    out: List[Path] = []
    for code in locale_codes:
        lproj = lang_root_dir / code_to_lproj(code)
        for bf in base_files:
            p = lproj / bf.name
            if p.exists():
                out.append(p)
    return out


def dupcheck_report(files: List[Path]) -> Dict[str, Dict[str, int]]:
    report: Dict[str, Dict[str, int]] = {}
    for p in files:
        parsed = parse_strings_file(p)
        dups = find_duplicates(parsed.entries)
        if dups:
            report[str(p)] = {k: len(v) for k, v in dups.items()}
    return report


def dedupe_batch(files: List[Path], keep: str, dry: bool) -> Dict[str, int]:
    changed_files = 0
    for p in files:
        parsed = parse_strings_file(p)
        dups = find_duplicates(parsed.entries)
        if not dups:
            continue

        if keep == "first":
            seen: Set[str] = set()

            def keep_pred(e: StringsEntry) -> bool:
                if e.key in seen:
                    return False
                seen.add(e.key)
                return True

        else:
            last_idx: Dict[str, int] = {}
            for i, e in enumerate(parsed.entries):
                last_idx[e.key] = i
            cur = {"i": -1}

            def keep_pred(e: StringsEntry) -> bool:
                cur["i"] += 1
                return last_idx.get(e.key) == cur["i"]

        new_parsed = filter_entries_with_carry(parsed, keep_pred)
        if write_parsed_strings(p, new_parsed, dry):
            changed_files += 1

    return {"changed_files": changed_files}


def redundant_report(
        *,
        base_dir: Path,
        base_files: List[Path],
        targets: List[Path],
) -> Dict[str, Dict[str, List[str]]]:
    base_keys_map: Dict[str, Set[str]] = {}
    for bf in base_files:
        base_path = base_dir / bf.name
        base_keys_map[bf.name] = {e.key for e in parse_strings_file(base_path).entries}

    rep: Dict[str, Dict[str, List[str]]] = {}
    for t in targets:
        parsed = parse_strings_file(t)

        # æ‰¾åˆ°è¯¥ target å¯¹åº”çš„ base æ–‡ä»¶åï¼ˆæŒ‰æ–‡ä»¶åï¼‰
        base_name = t.name
        base_keys = base_keys_map.get(base_name, set())

        extra = sorted({e.key for e in parsed.entries if e.key not in base_keys}, key=str.lower)
        if extra:
            rep.setdefault(str(t), {})
            rep[str(t)][base_name] = extra

    return rep


def clean_redundant_batch(report: Dict[str, Dict[str, List[str]]], dry: bool) -> Dict[str, int]:
    changed_files = 0
    removed_keys = 0

    for file_path, per_base in report.items():
        redundant_keys: Set[str] = set()
        for _, ks in per_base.items():
            redundant_keys.update(ks)

        p = Path(file_path)
        parsed = parse_strings_file(p)
        new_parsed = filter_entries_with_carry(parsed, lambda e: e.key not in redundant_keys)

        if write_parsed_strings(p, new_parsed, dry):
            changed_files += 1
        removed_keys += len(redundant_keys)

    return {"changed_files": changed_files, "removed_keys": removed_keys, "files": len(report)}


# =========================================================
# Translation helpers
# =========================================================
def _get_api_key(passed: Optional[str]) -> Optional[str]:
    if passed:
        return passed
    env = os.getenv("OPENAI_API_KEY", "").strip()
    if env:
        return env
    s = input("æœªæ£€æµ‹åˆ° OPENAI_API_KEYã€‚è¯·è¾“å…¥ apiKeyï¼ˆç›´æ¥å›è½¦å–æ¶ˆç¿»è¯‘ï¼‰: ").strip()
    return s or None


def _fmt_pct(n: int, total: int) -> str:
    if total <= 0:
        return "0.0%"
    return f"{(n * 100.0 / total):5.1f}%"


def _fmt_eta(elapsed_s: float, done: int, total: int) -> str:
    if done <= 0 or total <= 0:
        return "--:--"
    remain = max(total - done, 0)
    rate = elapsed_s / done
    eta = int(remain * rate)
    mm = eta // 60
    ss = eta % 60
    return f"{mm:02d}:{ss:02d}"


def _fmt_locale_names(locales: List[Dict[str, str]], *, max_show: int = 10) -> str:
    names = [str(x.get("name_en", "")).strip() for x in locales if str(x.get("name_en", "")).strip()]
    if len(names) <= max_show:
        return ", ".join(names)
    head = ", ".join(names[:max_show])
    return f"{head} ...ï¼ˆå…± {len(names)} ä¸ªï¼‰"


def _prompt_for_target(cfg: Dict[str, Any], src_code: str, src_name_en: str, tgt_code: str, tgt_name_en: str) -> Optional[str]:
    prompts = cfg.get("prompts") or {}
    default_en = (prompts.get("default_en") or "").strip()
    by_locale = prompts.get("by_locale_en") or {}
    extra = (by_locale.get(tgt_code) or by_locale.get(tgt_code.replace("_", "-")) or "").strip()

    guard = (
        "You are translating UI strings for an iOS app.\n"
        f"Source locale code: {src_code}\n"
        f"Source language (English name): {src_name_en}\n"
        f"Target locale code: {tgt_code}\n"
        f"Target language (English name): {tgt_name_en}\n"
        "Rules:\n"
        f"- Output MUST be written in {tgt_name_en}.\n"
        "- Do NOT output any other language.\n"
        "- Do NOT output Chinese unless the target language is Chinese.\n"
        "- Keep placeholders/variables/formatting tokens unchanged.\n"
        "- Keep meaning accurate and natural for iOS UI.\n"
    ).strip()

    parts: List[str] = []
    if default_en:
        parts.append(default_en)
    if extra:
        parts.append(extra)
    parts.append(guard)
    combo = "\n\n".join(parts).strip()
    return combo or None


def _parsed_to_first_dict(parsed: ParsedStrings) -> Dict[str, str]:
    out: Dict[str, str] = {}
    for e in parsed.entries:
        if e.key not in out:
            out[e.key] = e.value
    return out


def _update_or_append_entries(parsed: ParsedStrings, updates: Dict[str, str]) -> ParsedStrings:
    if not updates:
        return parsed

    seen: Set[str] = set()
    new_entries: List[StringsEntry] = []
    for e in parsed.entries:
        if e.key in updates and e.key not in seen:
            seen.add(e.key)
            new_entries.append(StringsEntry(e.key, updates[e.key], e.comments, e.raw_before))
        else:
            new_entries.append(e)

    existing = {e.key for e in parsed.entries}
    for k, v in updates.items():
        if k not in existing:
            new_entries.append(StringsEntry(k, v, [], []))

    return ParsedStrings(parsed.header[:], new_entries, parsed.tail[:])


def incremental_translate_one_file(
        *,
        cfg: Dict[str, Any],
        api_key: str,
        model: str,
        src_file: Path,
        src_name_en: str,
        tgt_file: Path,
        tgt_code: str,
        tgt_name_en: str,
        full: bool,
        cleanup_extra: bool,
        dry: bool,
) -> Dict[str, int]:
    src_parsed = parse_strings_file(src_file)
    src_map = _parsed_to_first_dict(src_parsed)
    if not src_map:
        return {"needed": 0, "changed": 0}

    tgt_parsed = parse_strings_file(tgt_file)
    tgt_map = _parsed_to_first_dict(tgt_parsed)

    if cleanup_extra:
        tgt_map = {k: v for k, v in tgt_map.items() if k in src_map}

    if full:
        need = dict(src_map)
    else:
        need = {k: v for k, v in src_map.items() if (k not in tgt_map) or (str(tgt_map.get(k, "")).strip() == "")}

    if not need:
        return {"needed": 0, "changed": 0}

    prompt_en = _prompt_for_target(cfg, src_code="(strings)", src_name_en=src_name_en, tgt_code=tgt_code, tgt_name_en=tgt_name_en)
    translated = translate_flat_dict(
        prompt_en=prompt_en,
        src_dict=need,
        src_lang=src_name_en,
        tgt_locale=tgt_name_en,
        model=model,
        api_key=api_key,
    )

    new_parsed = _update_or_append_entries(tgt_parsed, translated)
    changed = write_parsed_strings(tgt_file, new_parsed, dry)
    return {"needed": len(need), "changed": 1 if changed else 0}


def translate_batch(
        *,
        project_root: Path,
        cfg: Dict[str, Any],
        base_dir: Path,
        base_files: List[Path],
        lang_root_dir: Path,
        src_dir: Path,
        src_name_en: str,
        targets: List[Dict[str, str]],
        api_key: str,
        model: str,
        full: bool,
        dry: bool,
        src_code: Optional[str] = None,
) -> Dict[str, int]:
    cleanup_extra = bool(cfg["options"]["cleanup_extra_keys"])

    # é¢„æ‰«æï¼šæ”¶é›†æ‰€æœ‰éœ€è¦ç¿»è¯‘çš„ä»»åŠ¡
    task_queue: List[Tuple[Dict[str, str], Path, int]] = []
    src_display = src_code if src_code else "Base.lproj"

    for t in targets:
        tgt_code = t["code"]
        tgt_lproj = lang_root_dir / code_to_lproj(tgt_code)
        ensure_dir(tgt_lproj, dry=True)
        for bf in base_files:
            src_file = src_dir / bf.name
            if not src_file.exists():
                continue
            tgt_file = tgt_lproj / bf.name
            ensure_file(tgt_file, dry=True)
            r = incremental_translate_one_file(
                cfg=cfg,
                api_key=api_key,
                model=model,
                src_file=src_file,
                src_name_en=src_name_en,
                tgt_file=tgt_file,
                tgt_code=tgt_code,
                tgt_name_en=t["name_en"],
                full=full,
                cleanup_extra=cleanup_extra,
                dry=True,
            )
            if r["needed"] > 0:
                task_queue.append((t, bf, r["needed"]))

    effective_tasks = len(task_queue)
    if effective_tasks == 0:
        print("âœ… æ— éœ€ç¿»è¯‘ï¼šæ‰€æœ‰ç›®æ ‡æ–‡ä»¶å·²é½å…¨")
        return {"effective_tasks": 0, "files_changed": 0, "keys_translated": 0}

    # æ˜¾ç¤ºç¿»è¯‘ä»»åŠ¡æ¦‚è§ˆ
    mode_text = "å…¨é‡" if full else "å¢é‡"
    print(f"\nğŸŒ ç¿»è¯‘ä»»åŠ¡ï¼š{src_display} ({src_name_en}) â†’ "
          f"{len(targets)} ä¸ªç›®æ ‡è¯­è¨€")
    print(f"ğŸ§® æœ‰æ•ˆä»»åŠ¡æ•°ï¼ˆéœ€ç¿»è¯‘ï¼‰ï¼š{effective_tasks:,} ä¸ªï¼›"
          f"æ¨¡å¼={mode_text}ï¼›model={model}")

    # æ˜¾ç¤ºæ’é˜Ÿä¸­çš„ä»»åŠ¡åˆ—è¡¨
    if effective_tasks > 0:
        print(f"\nğŸ“‹ æ’é˜Ÿä¸­çš„ä»»åŠ¡ï¼ˆ{effective_tasks:,} ä¸ªï¼‰ï¼š")
        for idx, (t, bf, needed) in enumerate(task_queue[:10], 1):
            print(f"   {idx}. {src_display} â†’ {t['code']} ({t['name_en']}) / "
                  f"{bf.name} | éœ€ç¿»è¯‘ {needed} keys")
        if effective_tasks > 10:
            print(f"   ... è¿˜æœ‰ {effective_tasks - 10} ä¸ªä»»åŠ¡")
        print()

    done = 0
    changed_files = 0
    translated_keys = 0
    start = time.time()

    for idx, (t, bf, expected_needed) in enumerate(task_queue, 1):
        tgt_code = t["code"]
        tgt_name_en = t["name_en"]
        tgt_lproj = lang_root_dir / code_to_lproj(tgt_code)
        ensure_dir(tgt_lproj, dry)

        src_file = src_dir / bf.name
        tgt_file = tgt_lproj / bf.name
        ensure_file(tgt_file, dry)

        # æ˜¾ç¤ºç¿»è¯‘ä¸­çŠ¶æ€
        print(f"ğŸ”„ [{idx}/{effective_tasks}] ç¿»è¯‘ä¸­ï¼š"
              f"{src_display} â†’ {tgt_code} ({tgt_name_en}) / {bf.name}")

        r = incremental_translate_one_file(
            cfg=cfg,
            api_key=api_key,
            model=model,
            src_file=src_file,
            src_name_en=src_name_en,
            tgt_file=tgt_file,
            tgt_code=tgt_code,
            tgt_name_en=tgt_name_en,
            full=full,
            cleanup_extra=cleanup_extra,
            dry=dry,
        )

        if r["needed"] <= 0:
            print("   â­ï¸  è·³è¿‡ï¼ˆæ— éœ€ç¿»è¯‘ï¼‰")
            continue

        done += 1
        translated_keys += int(r["needed"])
        changed_files += int(r["changed"])

        elapsed = time.time() - start
        eta = _fmt_eta(elapsed, done, effective_tasks)
        pct = _fmt_pct(done, effective_tasks)
        flag = "å·²å†™å…¥" if r["changed"] else "æ— å˜åŒ–"
        print(
            f"   âœ… å®Œæˆ [{done}/{effective_tasks} | {pct} | "
            f"é¢„è®¡å‰©ä½™ {eta}] | éœ€ç¿»è¯‘={r['needed']:<4} | {flag}"
        )

    elapsed = time.time() - start
    mm, ss = divmod(int(elapsed), 60)
    print(
        f"\nâœ… ç¿»è¯‘å®Œæˆï¼šç”¨æ—¶ {mm:02d}:{ss:02d}ï¼›"
        f"æœ‰æ•ˆä»»åŠ¡ {effective_tasks:,} ä¸ªï¼›"
        f"æ”¹åŠ¨æ–‡ä»¶ {changed_files:,} ä¸ªï¼›"
        f"ç¿»è¯‘ keys {translated_keys:,} ä¸ª"
    )
    return {"effective_tasks": effective_tasks, "files_changed": changed_files, "keys_translated": translated_keys}




# =========================================================
# L10n.swift generator (from Base.lproj/Localizable.strings)
# =========================================================
_SWIFT_KEYWORDS = {
    "associatedtype", "class", "deinit", "enum", "extension", "fileprivate", "func", "import", "init",
    "inout", "internal", "let", "open", "operator", "private", "protocol", "public", "rethrows",
    "static", "struct", "subscript", "typealias", "var", "break", "case", "continue", "default",
    "defer", "do", "else", "fallthrough", "for", "guard", "if", "in", "repeat", "return", "switch",
    "where", "while", "as", "Any", "catch", "false", "is", "nil", "super", "self", "Self", "throw",
    "throws", "true", "try", "_", "#available", "#colorLiteral", "#column", "#file", "#function",
    "#line", "#selector", "#sourceLocation",
}


def _swift_escape_string(s: str) -> str:
    # Swift string literal escaping for " and \\ plus newlines.
    s = s.replace('\\', r'\\')
    s = s.replace('"', r'\"')
    s = s.replace('\r\n', '\n').replace('\r', '\n')
    s = s.replace('\n', r'\n')
    return s


def _upper_camel(parts: List[str]) -> str:
    out: List[str] = []
    for p in parts:
        p2 = re.sub(r"[^0-9A-Za-z]+", " ", p).strip()
        if not p2:
            continue
        ws = [w for w in p2.split() if w]
        for w in ws:
            out.append(w[:1].upper() + w[1:])
    return "".join(out) or "X"


def _lower_camel(parts: List[str]) -> str:
    uc = _upper_camel(parts)
    if not uc:
        return "x"
    return uc[:1].lower() + uc[1:]


def _swift_identifier(name: str, *, upper: bool) -> str:
    # name: raw segment(s)
    parts = [name]
    ident = _upper_camel(parts) if upper else _lower_camel(parts)
    if not ident:
        ident = "x"
    # identifiers cannot start with digit
    if ident[:1].isdigit():
        ident = "_" + ident
    if ident in _SWIFT_KEYWORDS:
        ident = ident + "_"
    return ident


def _swift_identifier_from_parts(parts: List[str], *, upper: bool) -> str:
    ident = _upper_camel(parts) if upper else _lower_camel(parts)
    if not ident:
        ident = "x"
    if ident[:1].isdigit():
        ident = "_" + ident
    if ident in _SWIFT_KEYWORDS:
        ident = ident + "_"
    return ident


def _comments_to_doc(lines: List[str]) -> List[str]:
    # Convert .strings comments into Swift doc comments.
    out: List[str] = []
    buf: List[str] = []
    for raw in lines:
        s = raw.strip("\n")
        s2 = s.strip()
        if not s2:
            continue
        # strip common comment markers
        if s2.startswith("/*"):
            s2 = s2[2:]
        if s2.endswith("*/"):
            s2 = s2[:-2]
        if s2.startswith("//"):
            s2 = s2[2:]
        s2 = s2.strip(" *\t")
        if s2:
            buf.append(s2)
    for line in buf:
        out.append(f"        /// {line}\n")
    return out


def generate_l10n_swift(
        *,
        project_root: Path,
        cfg: Dict[str, Any],
        out_path_arg: Optional[str],
        dry: bool,
) -> Path:
    lang_root_dir, base_dir = project_paths(project_root, cfg)
    src = base_dir / "Localizable.strings"
    if not src.exists():
        raise FileNotFoundError(f"âŒ æœªæ‰¾åˆ° Base çš„ Localizable.stringsï¼š{src}")

    # output path
    if out_path_arg and str(out_path_arg).strip():
        op = Path(str(out_path_arg).strip()).expanduser()
        if not op.is_absolute():
            op = (project_root / op).resolve()
        out_path = op
    else:
        out_path = (lang_root_dir / "L10n.swift").resolve()

    parsed = parse_strings_file(src)

    # Preserve base file order.
    groups: Dict[str, List[StringsEntry]] = {}
    group_order: List[str] = []
    for e in parsed.entries:
        parts = e.key.split(".")
        grp_raw = parts[0] if len(parts) > 1 else "Ungrouped"
        if grp_raw not in groups:
            groups[grp_raw] = []
            group_order.append(grp_raw)
        groups[grp_raw].append(e)

    # Build Swift
    out: List[str] = []
    out.append("// Auto-generated from Base.lproj/Localizable.strings\n")
    out.append("import Foundation\n\n")
    out.append("extension String {\n")
    out.append("    func callAsFunction(_ arguments: CVarArg...) -> String {\n")
    out.append("        String(format: self, locale: Locale.current, arguments: arguments)\n")
    out.append("    }\n")
    out.append("}\n\n")
    out.append("enum L10n {\n")

    for grp_raw in group_order:
        entries = groups[grp_raw]
        grp_name = _swift_identifier(grp_raw, upper=True)
        out.append(f"    enum {grp_name} {{\n")

        used: Dict[str, int] = {}
        for e in entries:
            # doc comments from Base entry
            doc = _comments_to_doc(e.comments)
            out.extend(doc)

            parts = e.key.split(".")
            if len(parts) > 1:
                rest = parts[1:]
            else:
                rest = parts
            prop = _swift_identifier_from_parts(rest, upper=False)
            if prop in used:
                used[prop] += 1
                prop2 = f"{prop}_{used[prop]}"
            else:
                used[prop] = 0
                prop2 = prop

            key_lit = _swift_escape_string(e.key)
            val_lit = _swift_escape_string(e.value)
            out.append(
                f"        static var {prop2}: String {{ return NSLocalizedString(\"{key_lit}\", value: \"{val_lit}\", comment: \"{val_lit}\") }}\n\n"
            )

        # trim last blank line inside group
        if out and out[-1] == "\n":
            out.pop()
        if out and out[-1].endswith("\n\n"):
            out[-1] = out[-1][:-1]

        out.append("    }\n\n")

    if out and out[-1] == "\n\n":
        out.pop()

    out.append("}\n")

    content = "".join(out)

    if dry:
        print(f"ï¼ˆdry-runï¼‰å°†ç”Ÿæˆï¼š{out_path}")
        return out_path

    out_path.parent.mkdir(parents=True, exist_ok=True)
    out_path.write_text(content, encoding="utf-8")
    print(f"âœ… å·²ç”Ÿæˆï¼š{out_path}")
    return out_path

# =========================================================
# Doctor
# =========================================================
def doctor(cfg_path: Path, api_key: Optional[str], languages_path: Path, project_root: Path) -> None:
    ok = True

    if OpenAI is None:
        ok = False
        print("âŒ OpenAI SDK ä¸å¯ç”¨ï¼špipx: pipx inject box 'openai>=1.0.0'")
    else:
        print("âœ… OpenAI SDK OK")

    try:
        _require_yaml()
        print("âœ… PyYAML OK")
    except SystemExit as e:
        ok = False
        print(str(e).strip())

    if not cfg_path.exists():
        ok = False
        print(f"âŒ æœªæ‰¾åˆ° {CONFIG_FILE}ï¼ˆè¯·å…ˆ strings_i18n initï¼‰")
        cfg = None
    else:
        try:
            cfg = read_config(cfg_path)
            print(f"âœ… {CONFIG_FILE} OKï¼ˆmodel={cfg.get('openAIModel')}ï¼‰")
        except Exception as e:
            ok = False
            cfg = None
            print(f"âŒ {CONFIG_FILE} è§£æå¤±è´¥ï¼š{e}")

    if not languages_path.exists():
        ok = False
        print(f"âŒ æœªæ‰¾åˆ° languages.jsonï¼š{languages_path}")
    else:
        try:
            langs = load_languages_json(languages_path)
            print(f"âœ… languages.json OKï¼ˆ{len(langs)} languagesï¼‰")
        except Exception as e:
            ok = False
            print(f"âŒ languages.json è§£æå¤±è´¥ï¼š{e}")

    if cfg is not None:
        try:
            lang_root_dir, base_dir = project_paths(project_root, cfg)
            if base_dir.exists() and base_dir.is_dir():
                base_files = [p.name for p in scan_base_strings(base_dir)]
                print(f"âœ… Base.lproj OKï¼ˆ{len(base_files)} files: {', '.join(base_files)}ï¼‰")
            else:
                ok = False
                print(f"âŒ Base ç›®å½•ä¸å­˜åœ¨ï¼š{base_dir}")
        except Exception as e:
            ok = False
            print(f"âŒ ç›®å½•ç»“æ„æ£€æŸ¥å¤±è´¥ï¼š{e}")

    ak = api_key or os.getenv("OPENAI_API_KEY")
    if not ak:
        print("âš ï¸ æœªæä¾› API Keyï¼š--api-key æˆ–ç¯å¢ƒå˜é‡ OPENAI_API_KEYï¼ˆç¿»è¯‘æ—¶éœ€è¦ï¼‰")
    else:
        print("âœ… API Key å·²é…ç½®ï¼ˆæ¥æºï¼šå‚æ•°æˆ–ç¯å¢ƒå˜é‡ï¼‰")

    if not ok:
        raise SystemExit(EXIT_BAD)
    print("âœ… doctor å®Œæˆ")


# =========================================================
# Interactive (slang_i18n style)
# =========================================================
def _read_choice(prompt: str, valid: Iterable[str]) -> str:
    valid_set = {v.lower() for v in valid}
    while True:
        s = input(prompt).strip().lower()
        if s in valid_set:
            return s
        if s in ("q", "quit", "exit"):
            return "0"
        print(f"è¯·è¾“å…¥ {' / '.join(sorted(valid_set))}ï¼ˆæˆ– q é€€å‡ºï¼‰")


def choose_action_interactive(project_root: Path, cfg_path: Path) -> str:
    # å°½åŠ›æ£€æµ‹ L10n.swift æ˜¯å¦å·²å­˜åœ¨ï¼š
    # - è‹¥ strings_i18n.yaml å¯è¯»ï¼Œåˆ™ä»¥ lang_root/L10n.swift ä¸ºå‡†
    # - å¦åˆ™å›é€€åˆ°é¡¹ç›®æ ¹ç›®å½•çš„ ./L10n.swift
    l10n_path = project_root / "L10n.swift"
    if cfg_path.exists():
        try:
            cfg = read_config(cfg_path)
            lang_root_dir, _ = project_paths(project_root, cfg)
            l10n_path = lang_root_dir / "L10n.swift"
        except Exception:
            pass

    exists_flag = "âœ… å·²å­˜åœ¨" if l10n_path.exists() else "â• å°†ç”Ÿæˆ"

    print("=== strings_i18n æ“ä½œå° ===")
    print(f"1 - gen-l10nï¼ˆç”Ÿæˆ L10n.swiftï¼š{exists_flag}ï¼‰")
    print("2 - sortï¼ˆå…ˆæ’åº Baseï¼šä¿ç•™æ³¨é‡Šã€æŒ‰å‰ç¼€åˆ†ç»„ï¼›å†æŒ‰ Base é¡ºåºæ’åºå…¶å®ƒè¯­è¨€ï¼‰")
    print("3 - translate-coreï¼ˆå¢é‡ç¿»è¯‘ï¼šbase_locale â†’ core_localesï¼›æ‰“å° {{base_locale.name_en}} â†’ {{core_locales.name_en åˆ—è¡¨}}ï¼‰")
    print("4 - translate-targetï¼ˆå¢é‡ç¿»è¯‘ï¼šsource_locale â†’ target_localesï¼›ç›®æ ‡è¶…è¿‡ 10 ä¸ªæˆªæ–­å¹¶æ˜¾ç¤ºæ€»æ•°ï¼‰")
    print("5 - cleanupï¼ˆæ¸…ç†é‡å¤/å†—ä½™å­—æ®µï¼šBase é‡å¤ key åˆ—å‡ºï¼›å…¶å®ƒè¯­è¨€å†—ä½™ key å…¨åˆ—å¹¶æç¤ºæ˜¯å¦åˆ é™¤ï¼‰")
    print("6 - doctorï¼ˆæ£€æŸ¥ç¯å¢ƒ/é…ç½®/ç›®å½•ç»“æ„ï¼‰")
    print("0 / q - é€€å‡º")
    choice = _read_choice("è¯·è¾“å…¥ 0 / 1 / ... / 6ï¼ˆæˆ– q é€€å‡ºï¼‰: ", valid=[str(i) for i in range(0, 7)])
    if choice == "0":
        return "exit"
    return {
        "1": "gen-l10n",
        "2": "sort",
        "3": "translate-core",
        "4": "translate-target",
        "5": "cleanup",
        "6": "doctor",
    }[choice]


# =========================================================
# CLI
# =========================================================
def build_parser() -> argparse.ArgumentParser:
    p = argparse.ArgumentParser(
        prog="strings_i18n",
        description="iOS/Xcode .strings å¤šè¯­è¨€ï¼šæ‰«æ/åŒæ­¥/æ’åº/é‡å¤&å†—ä½™æ¸…ç†/å¢é‡ç¿»è¯‘ï¼ˆæ”¯æŒäº¤äº’ï¼‰",
    )
    p.add_argument(
        "action",
        nargs="?",
        choices=[
            "options",
            "init",
            "doctor",
            "scan",
            "sync",
            "sort",
            "dupcheck",
            "dedupe",
            "check",
            "clean",
            "cleanup",
            "translate-core",
            "translate-target",
            "gen-l10n",
        ],
        help="åŠ¨ä½œï¼ˆä¸å¡«åˆ™è¿›å…¥äº¤äº’èœå•ï¼‰",
    )
    p.add_argument("--config", default=CONFIG_FILE, help="é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ strings_i18n.yamlï¼‰")
    p.add_argument("--languages", default=LANG_FILE, help="languages.json è·¯å¾„ï¼ˆé»˜è®¤ languages.jsonï¼‰")
    p.add_argument("--project-root", default=".", help="é¡¹ç›®æ ¹ç›®å½•ï¼ˆé»˜è®¤å½“å‰ç›®å½•ï¼‰")
    p.add_argument("--api-key", default=None, help="OpenAI API keyï¼ˆä¹Ÿå¯ç”¨ç¯å¢ƒå˜é‡ OPENAI_API_KEYï¼‰")
    p.add_argument("--model", default=None, help=f"æ¨¡å‹ï¼ˆå‘½ä»¤è¡Œä¼˜å…ˆï¼›ä¸ä¼ åˆ™ç”¨é…ç½® openAIModelï¼›å…è®¸ï¼š{', '.join(ALLOWED_OPENAI_MODELS)}ï¼‰")
    p.add_argument("--full", action="store_true", help="å…¨é‡ç¿»è¯‘ï¼ˆé»˜è®¤å¢é‡ï¼‰")
    p.add_argument("--yes", action="store_true", help="åˆ é™¤æ—¶è·³è¿‡ç¡®è®¤ï¼ˆclean/dedupeï¼‰")
    p.add_argument("--keep", default="first", choices=["first", "last"], help="dedupe ä¿ç•™ç­–ç•¥ï¼ˆé»˜è®¤ firstï¼‰")
    p.add_argument("--no-exitcode-3", action="store_true", help="check/dupcheck å‘ç°é—®é¢˜æ—¶ä»è¿”å› 0ï¼ˆé»˜è®¤è¿”å› 3ï¼‰")
    p.add_argument("--dry-run", action="store_true", help="é¢„è§ˆæ¨¡å¼ï¼ˆä¸å†™å…¥æ–‡ä»¶ï¼‰")
    p.add_argument("--l10n-out", default=None, help="L10n.swift è¾“å‡ºè·¯å¾„ï¼ˆé»˜è®¤å†™å…¥ {lang_root}/L10n.swiftï¼›å¯ä¼ ç›¸å¯¹ project-root çš„è·¯å¾„ï¼‰")
    return p


def print_cli_options() -> None:
    """æ‰“å°å‘½ä»¤è¡Œç”¨æ³•ä¸ä¸»è¦é€‰é¡¹ï¼ˆç”¨äº CI / README å¤åˆ¶ç²˜è´´ï¼‰ã€‚"""
    print("=== strings_i18n CLI ç”¨æ³• ===")
    for u in BOX_TOOL.get("usage", []):
        print(f"  $ {u}")

    print("\n=== é€šç”¨é€‰é¡¹ ===")
    for opt in BOX_TOOL.get("options", []):
        flag = opt.get("flag", "")
        desc = opt.get("desc", "")
        if flag:
            print(f"  {flag:<16} {desc}")

    print("\nï¼ˆæç¤ºï¼‰æ¯ä¸ª action éƒ½æ”¯æŒ --dry-run é¢„è§ˆï¼›check/dupcheck é»˜è®¤åœ¨å‘ç°é—®é¢˜æ—¶è¿”å› exit code 3ã€‚")


def _cfg_one(cfg: Dict[str, Any], key: str) -> Dict[str, str]:
    lst = cfg.get(key)
    if not isinstance(lst, list) or not lst or not isinstance(lst[0], dict):
        raise ValueError(f"é…ç½®ç¼ºå°‘æˆ–æ ¼å¼é”™è¯¯ï¼š{key}ï¼ˆéœ€è¦ list[dict] ä¸”è‡³å°‘ 1 ä¸ªï¼‰")
    if not lst[0].get("code") or not lst[0].get("name_en"):
        raise ValueError(f"é…ç½® {key}[0] éœ€è¦åŒ…å« code ä¸ name_en")
    return {"code": str(lst[0]["code"]).strip(), "name_en": str(lst[0]["name_en"]).strip()}


def _cfg_list(cfg: Dict[str, Any], key: str) -> List[Dict[str, str]]:
    lst = cfg.get(key, [])
    if not isinstance(lst, list):
        raise ValueError(f"é…ç½®å­—æ®µæ ¼å¼é”™è¯¯ï¼š{key}ï¼ˆéœ€è¦ listï¼‰")
    out: List[Dict[str, str]] = []
    for it in lst:
        if isinstance(it, dict) and it.get("code") and it.get("name_en"):
            out.append({"code": str(it["code"]).strip(), "name_en": str(it["name_en"]).strip()})
    return out


def _pick_model(args_model: Optional[str], cfg: Dict[str, Any]) -> str:
    m = (args_model or "").strip() or str(cfg.get("openAIModel") or "").strip() or OpenAIModel.GPT_4O.value
    if m not in set(ALLOWED_OPENAI_MODELS):
        raise ValueError(f"âŒ model ä¸åˆæ³•ï¼š{m!r}ï¼Œå¯é€‰ï¼š{', '.join(ALLOWED_OPENAI_MODELS)}")
    return m


def main(argv: Optional[List[str]] = None) -> int:
    argv = sys.argv[1:] if argv is None else argv
    args = build_parser().parse_args(argv)

    project_root = Path(args.project_root).expanduser().resolve()
    cfg_path = Path(args.config).expanduser()
    if not cfg_path.is_absolute():
        cfg_path = project_root / cfg_path

    languages_path = Path(args.languages).expanduser()
    if not languages_path.is_absolute():
        languages_path = project_root / languages_path

    action = args.action
    interactive = False
    if not action:
        interactive = True
        action = choose_action_interactive(project_root=project_root, cfg_path=cfg_path)
        if action == "exit":
            return EXIT_OK

    if action == "init":
        try:
            init_config(cfg_path, project_root=project_root, languages_path=languages_path)
            return EXIT_OK
        except Exception as e:
            print(str(e))
            return EXIT_BAD

    if action == "options":
        print_cli_options()
        return EXIT_OK

    if action == "doctor":
        try:
            doctor(cfg_path, api_key=args.api_key, languages_path=languages_path, project_root=project_root)
            return EXIT_OK
        except SystemExit as e:
            return int(getattr(e, "code", EXIT_BAD))
        except Exception as e:
            print(str(e))
            return EXIT_BAD

    # below require cfg + project structure
    try:
        cfg = read_config_or_throw(cfg_path)
    except Exception as e:
        print(str(e))
        return EXIT_BAD

    # model selection: CLI > config > default
    try:
        model = _pick_model(args.model, cfg)
    except Exception as e:
        print(str(e))
        return EXIT_BAD

    # paths
    try:
        lang_root_dir, base_dir = project_paths(project_root, cfg)
        base_files = scan_base_strings(base_dir)
    except Exception as e:
        print(str(e))
        return EXIT_BAD

    # languages.json
    try:
        langs = load_languages_json(languages_path)
        all_codes = [x["code"] for x in langs]
    except Exception as e:
        print(str(e))
        return EXIT_BAD

    dry = bool(args.dry_run)

    if action == "cleanup":
        # ç›®æ ‡æ–‡ä»¶ï¼šæ‰€æœ‰è¯­è¨€ï¼ˆé™¤ Base ç›®å½•å¤–ï¼‰ï¼Œå­˜åœ¨çš„ *.strings
        try:
            target_files = collect_existing_target_files(
                lang_root_dir=lang_root_dir,
                base_files=base_files,
                locale_codes=all_codes,
            )
        except Exception as e:
            print(f"âŒ cleanup å¤±è´¥ï¼š{e}")
            return EXIT_FAIL

        # 1) é‡å¤ keyï¼šè‡³å°‘åŒ…å« Baseï¼›ä¹ŸæŠŠç›®æ ‡è¯­è¨€ä¸€èµ·æ£€æŸ¥ï¼Œé¿å…â€œåªä¿® Base ç»“æœåˆ«å¤„è¿˜ç‚¸â€
        base_paths = [base_dir / bf.name for bf in base_files]
        dup_files = base_paths + target_files
        dup_rep = dupcheck_report(dup_files)
        if dup_rep:
            print("=== é‡å¤ keyï¼ˆå« Baseï¼‰===")
            for fp, items in dup_rep.items():
                print(f"\nâ€¢ {fp}")
                for k, cnt in sorted(items.items(), key=lambda x: x[0].lower()):
                    print(f"  - {k}  (é‡å¤ {cnt} æ¬¡)")

            do_dedupe = bool(args.yes)
            if not args.yes:
                ans = input(f"\nå‘ç°é‡å¤ keyã€‚æ˜¯å¦è¦ç«‹å³åˆ é™¤é‡å¤é¡¹ï¼ˆä¿ç•™ {args.keep}ï¼‰ï¼Ÿè¾“å…¥ y åˆ é™¤ï¼Œå…¶ä»–é”®ä»…æ£€æŸ¥ï¼š").strip().lower()
                do_dedupe = ans in ("y", "yes", "1")

            if do_dedupe:
                stats = dedupe_batch(dup_files, keep=str(args.keep), dry=dry)
                if dry:
                    print("ï¼ˆdry-runï¼šæœªå†™å…¥ï¼‰")
                print(f"âœ… dedupe å®Œæˆï¼šæ”¹åŠ¨æ–‡ä»¶ {stats['changed_files']} ä¸ªï¼ˆä¿ç•™ {args.keep}ï¼‰")
        else:
            print("âœ… æœªå‘ç°é‡å¤ keyï¼ˆå« Baseï¼‰")

        # 2) å†—ä½™ keyï¼šBase æ²¡æœ‰ä½†ç›®æ ‡æœ‰ï¼ˆå…¨éƒ¨åˆ—å‡ºï¼‰
        red_rep = redundant_report(base_dir=base_dir, base_files=base_files, targets=target_files)
        if red_rep:
            print("\n=== å†—ä½™ keyï¼ˆBase æ²¡æœ‰ä½†ç›®æ ‡æœ‰ï¼‰===")
            total_files = 0
            total_keys = 0
            for fp, per_base in red_rep.items():
                total_files += 1
                for _, ks in per_base.items():
                    total_keys += len(ks)
                print(f"\nâ€¢ {fp}")
                # per_base çš„ key æ˜¯ base æ–‡ä»¶åï¼ˆé€šå¸¸åªæœ‰ä¸€ä¸ªï¼‰
                for _, ks in per_base.items():
                    for k in ks:
                        print(f"  - {k}")

            do_delete = bool(args.yes)
            if not args.yes:
                ans = input("\nå‘ç°å†—ä½™ keyã€‚æ˜¯å¦è¦ç«‹å³åˆ é™¤ï¼Ÿè¾“å…¥ y åˆ é™¤ï¼Œå…¶ä»–é”®ä»…æ£€æŸ¥ï¼š").strip().lower()
                do_delete = ans in ("y", "yes", "1")

            if do_delete:
                stats = clean_redundant_batch(red_rep, dry=dry)
                if dry:
                    print("ï¼ˆdry-runï¼šæœªå†™å…¥ï¼‰")
                print(
                    f"âœ… clean å®Œæˆï¼šæ”¹åŠ¨æ–‡ä»¶ {stats['changed_files']} / {stats['files']}ï¼Œåˆ é™¤å†—ä½™ key {stats['removed_keys']} ä¸ª"
                )
        else:
            print("\nâœ… æœªå‘ç°å†—ä½™ keyï¼ˆBase æ²¡æœ‰ä½†ç›®æ ‡æœ‰ï¼‰")

        # é‡å¤/å†—ä½™é»˜è®¤éƒ½å±äºâ€œå‘ç°é—®é¢˜â€
        found = bool(dup_rep) or bool(red_rep)
        if found and not bool(args.no_exitcode_3):
            return EXIT_FOUND
        return EXIT_OK

    if action == "gen-l10n":
        try:
            p = generate_l10n_swift(
                project_root=project_root,
                cfg=cfg,
                out_path_arg=args.l10n_out,
                dry=dry,
            )
            if dry:
                print("ï¼ˆdry-runï¼šæœªå†™å…¥ï¼‰")
            return EXIT_OK
        except Exception as e:
            print(f"âŒ gen-l10n å¤±è´¥ï¼š{e}")
            return EXIT_FAIL

    if action == "scan":
        print(f"âœ… Base ç›®å½•ï¼š{base_dir}")
        print("âœ… Base æ–‡ä»¶æ¸…å•ï¼š")
        for p in base_files:
            print(f"  â€¢ {p.name}")
        return EXIT_OK

    if action == "sync":
        try:
            result = sync_language_dirs_and_files(
                lang_root_dir=lang_root_dir,
                base_files=base_files,
                locale_codes=all_codes,
                dry=dry,
            )
            if result["created_dirs"]:
                print("â• åˆ›å»ºç›®å½•ï¼š")
                for d in result["created_dirs"]:
                    print(f"  â€¢ {d}")
            if result["created_files"]:
                print("â• åˆ›å»ºæ–‡ä»¶ï¼š")
                for f in result["created_files"]:
                    print(f"  â€¢ {f}")
            print(f"âœ… å·²å­˜åœ¨ï¼šç›®å½• {result['existing_dirs']:,}ï¼›æ–‡ä»¶ {result['existing_files']:,}")
            if dry:
                print("ï¼ˆdry-runï¼šæœªå†™å…¥ï¼‰")
            return EXIT_OK
        except Exception as e:
            print(f"âŒ sync å¤±è´¥ï¼š{e}")
            return EXIT_FAIL

    if action == "sort":
        try:
            res = sort_all(
                lang_root_dir=lang_root_dir,
                base_dir=base_dir,
                base_files=base_files,
                locale_codes=all_codes,
                dry=dry,
            )
            print(
                f"âœ… sort å®Œæˆï¼šBase æ”¹åŠ¨ {res.get('base_changed', 0):,} ä¸ªæ–‡ä»¶ï¼›"
                f"å…¶å®ƒè¯­è¨€å¤„ç† {res['total']:,}ï¼›æ”¹åŠ¨ {res['changed']:,}ï¼›ç¼ºå¤± {res['missing']:,}"
            )
            if dry:
                print("ï¼ˆdry-runï¼šæœªå†™å…¥ï¼‰")
            return EXIT_OK
        except Exception as e:
            print(f"âŒ sort å¤±è´¥ï¼š{e}")
            return EXIT_FAIL

    # build existing target list for dup/redundant
    existing_targets = collect_existing_target_files(
        lang_root_dir=lang_root_dir,
        base_files=base_files,
        locale_codes=all_codes,
    )
    base_paths_for_check = [base_dir / bf.name for bf in base_files if (base_dir / bf.name).exists()]

    if action == "dupcheck":
        try:
            rep = dupcheck_report(base_paths_for_check + existing_targets)
            if not rep:
                print("âœ… æœªå‘ç°é‡å¤ key")
                return EXIT_OK

            files_n = len(rep)
            groups_n = sum(len(v) for v in rep.values())
            print(f"âš ï¸ å‘ç°é‡å¤ï¼šæ¶‰åŠ {files_n} ä¸ªæ–‡ä»¶ï¼ˆåŒ…å« Baseï¼‰ï¼Œå…± {groups_n} ç»„é‡å¤ key")
            for fp, m in sorted(rep.items(), key=lambda kv: (-len(kv[1]), kv[0].lower())):
                items = sorted(m.items(), key=lambda kv: (-kv[1], kv[0].lower()))
                show = items[:20]
                print(f"\n- {fp}ï¼ˆ{len(items)} ç»„ï¼‰")
                for k, c in show:
                    print(f"  â€¢ {k}  x{c}")
                if len(items) > len(show):
                    print(f"  ... å¦å¤–è¿˜æœ‰ {len(items) - len(show)} ç»„æœªæ˜¾ç¤º")

            if args.no_exitcode_3:
                return EXIT_OK
            return EXIT_FOUND
        except Exception as e:
            print(f"âŒ dupcheck å¤±è´¥ï¼š{e}")
            return EXIT_FAIL

    if action == "dedupe":
        try:
            rep = dupcheck_report(existing_targets)
            if not rep:
                print("âœ… æœªå‘ç°é‡å¤ key")
                return EXIT_OK

            # ä¸€æ¬¡æ€§ç¡®è®¤
            if not args.yes:
                ans = _read_choice("ç¡®è®¤æ‰¹é‡åˆ é™¤ä»¥ä¸Šé‡å¤ keyï¼Ÿè¯·è¾“å…¥ 1 åˆ é™¤ / 0 å–æ¶ˆ: ", valid=["0", "1"])
                if ans != "1":
                    print("ğŸ§Š å·²å–æ¶ˆ")
                    return EXIT_OK

            targets = [Path(p) for p in rep.keys()]
            r = dedupe_batch(targets, keep=args.keep, dry=dry)
            print(f"âœ… dedupe å®Œæˆï¼šæ”¹åŠ¨æ–‡ä»¶ {r['changed_files']:,}ï¼ˆkeep={args.keep}ï¼‰")
            if dry:
                print("ï¼ˆdry-runï¼šæœªå†™å…¥ï¼‰")
            return EXIT_OK
        except Exception as e:
            print(f"âŒ dedupe å¤±è´¥ï¼š{e}")
            return EXIT_FAIL

    if action == "check":
        try:
            rep = redundant_report(base_dir=base_dir, base_files=base_files, targets=existing_targets)
            if not rep:
                print("âœ… æœªå‘ç°å†—ä½™ keyï¼ˆBase æ²¡æœ‰ä½†ç›®æ ‡æœ‰ï¼‰")
                return EXIT_OK

            files_n = len(rep)
            keys_n = sum(len(ks) for per_base in rep.values() for ks in per_base.values())
            print(f"âš ï¸ å‘ç°å†—ä½™ keyï¼šæ¶‰åŠ {files_n} ä¸ªæ–‡ä»¶ï¼Œå…± {keys_n} ä¸ªå†—ä½™ key")
            for fp, per_base in sorted(rep.items(), key=lambda kv: (-sum(len(ks) for ks in kv[1].values()), kv[0].lower())):
                total_keys = sum(len(ks) for ks in per_base.values())
                print(f"\n- {fp}ï¼ˆ{total_keys} ä¸ªå†—ä½™ keyï¼‰")
                for base_name, ks in per_base.items():
                    # éœ€æ±‚ï¼šå…¨éƒ¨åˆ—å‡ºï¼ˆé¿å…è¯¯åˆ ï¼‰
                    for k in ks:
                        print(f"  â€¢ {k}")

            # éœ€æ±‚ï¼šåœ¨ check ä¸­ç›´æ¥æç¤ºæ˜¯å¦è¦åˆ é™¤
            ans = _read_choice("\næ˜¯å¦ç«‹å³åˆ é™¤ä»¥ä¸Šå†—ä½™ keyï¼Ÿè¯·è¾“å…¥ 1 åˆ é™¤ / 0 ä»…æ£€æŸ¥: ", valid=["0", "1"])
            if ans == "1":
                r = clean_redundant_batch(rep, dry=dry)
                print(f"âœ… å·²åˆ é™¤å†—ä½™ keyï¼šæ”¹åŠ¨æ–‡ä»¶ {r['changed_files']:,}ï¼›åˆ é™¤ key {r['removed_keys']:,}")
                if dry:
                    print("ï¼ˆdry-runï¼šæœªå†™å…¥ï¼‰")
                return EXIT_OK

            if args.no_exitcode_3:
                return EXIT_OK
            return EXIT_FOUND
        except Exception as e:
            print(f"âŒ check å¤±è´¥ï¼š{e}")
            return EXIT_FAIL

    if action == "clean":
        try:
            rep = redundant_report(base_dir=base_dir, base_files=base_files, targets=existing_targets)
            if not rep:
                print("âœ… æœªå‘ç°å†—ä½™ key")
                return EXIT_OK

            # ä¸€æ¬¡æ€§ç¡®è®¤
            keys_n = sum(len(ks) for per_base in rep.values() for ks in per_base.values())
            if not args.yes:
                ans = _read_choice(f"ç¡®è®¤æ‰¹é‡åˆ é™¤ä»¥ä¸Š {len(rep)} ä¸ªæ–‡ä»¶ä¸­çš„ {keys_n} ä¸ªå†—ä½™ keyï¼Ÿè¯·è¾“å…¥ 1 åˆ é™¤ / 0 å–æ¶ˆ: ", valid=["0", "1"])
                if ans != "1":
                    print("ğŸ§Š å·²å–æ¶ˆ")
                    return EXIT_OK

            r = clean_redundant_batch(rep, dry=dry)
            print(f"âœ… clean å®Œæˆï¼šæ”¹åŠ¨æ–‡ä»¶ {r['changed_files']:,}ï¼›åˆ é™¤ key {r['removed_keys']:,}")
            if dry:
                print("ï¼ˆdry-runï¼šæœªå†™å…¥ï¼‰")
            return EXIT_OK
        except Exception as e:
            print(f"âŒ clean å¤±è´¥ï¼š{e}")
            return EXIT_FAIL

    if action == "translate-core":
        try:
            base_locale = _cfg_one(cfg, "base_locale")
            core_locales = _cfg_list(cfg, "core_locales")
            if not core_locales:
                print("âŒ core_locales ä¸ºç©ºï¼ˆé…ç½®é”™è¯¯ï¼‰")
                return EXIT_BAD

            api_key = _get_api_key(args.api_key)
            if not api_key:
                print("âŒ æœªæä¾› API Keyï¼ˆç¿»è¯‘éœ€è¦ï¼‰")
                return EXIT_BAD

            full = bool(args.full) or not bool(
                cfg["options"]["incremental_translate"]
            )

            # æ˜¾ç¤ºç¿»è¯‘ä»»åŠ¡ä¿¡æ¯
            print("\nğŸ“‹ ç¿»è¯‘ä»»åŠ¡ï¼šbase_locale â†’ core_locales")
            print(f"   æºè¯­è¨€ï¼šBase.lproj | {base_locale['name_en']}")
            print(f"   ç›®æ ‡è¯­è¨€ï¼ˆæ ¸å¿ƒï¼‰ï¼š{_fmt_locale_names(core_locales, max_show=999)}")

            translate_batch(
                project_root=project_root,
                cfg=cfg,
                base_dir=base_dir,
                base_files=base_files,
                lang_root_dir=lang_root_dir,
                src_dir=base_dir,
                src_name_en=base_locale["name_en"],
                targets=core_locales,
                api_key=api_key,
                model=model,
                full=full,
                dry=dry,
                src_code="Base.lproj",
            )
            return EXIT_OK
        except TranslationError as e:
            print(f"âŒ TranslationError: {e}")
            return EXIT_FAIL
        except Exception as e:
            print(f"âŒ translate-core å¤±è´¥ï¼š{e}")
            return EXIT_FAIL

    if action == "translate-target":
        try:
            source_locale = _cfg_one(cfg, "source_locale")
            target_locales = _cfg_list(cfg, "target_locales")
            if not target_locales:
                print("âŒ target_locales ä¸ºç©ºï¼ˆé…ç½®é”™è¯¯ï¼‰")
                return EXIT_BAD

            api_key = _get_api_key(args.api_key)
            if not api_key:
                print("âŒ æœªæä¾› API Keyï¼ˆç¿»è¯‘éœ€è¦ï¼‰")
                return EXIT_BAD

            src_code = source_locale["code"]
            src_dir = lang_root_dir / code_to_lproj(src_code)
            if not src_dir.exists() or not src_dir.is_dir():
                print(f"âŒ æºè¯­è¨€ç›®å½•ä¸å­˜åœ¨ï¼š{src_dir}")
                return EXIT_BAD

            full = bool(args.full) or not bool(
                cfg["options"]["incremental_translate"]
            )

            # æ˜¾ç¤ºç¿»è¯‘ä»»åŠ¡ä¿¡æ¯
            print("\nğŸ“‹ ç¿»è¯‘ä»»åŠ¡ï¼šsource_locale â†’ target_locales")
            print(f"   æºè¯­è¨€ï¼š{src_code} | {source_locale['name_en']}")
            print(f"   ç›®æ ‡è¯­è¨€ï¼ˆå…¶å®ƒï¼‰ï¼š{_fmt_locale_names(target_locales, max_show=10)}")

            translate_batch(
                project_root=project_root,
                cfg=cfg,
                base_dir=base_dir,
                base_files=base_files,
                lang_root_dir=lang_root_dir,
                src_dir=src_dir,
                src_name_en=source_locale["name_en"],
                targets=target_locales,
                api_key=api_key,
                model=model,
                full=full,
                dry=dry,
                src_code=src_code,
            )
            return EXIT_OK
        except TranslationError as e:
            print(f"âŒ TranslationError: {e}")
            return EXIT_FAIL
        except Exception as e:
            print(f"âŒ translate-target å¤±è´¥ï¼š{e}")
            return EXIT_FAIL

    print(f"âŒ æœªçŸ¥ actionï¼š{action}")
    return EXIT_BAD


if __name__ == "__main__":
    try:
        raise SystemExit(main())
    except KeyboardInterrupt:
        print("\nå·²å–æ¶ˆã€‚")
        raise SystemExit(130)
